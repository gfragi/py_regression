2022-11-18 00:46:08,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 00:46:08,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 00:46:08,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 00:46:08,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 01:10:00,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 01:10:00,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 01:10:00,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 01:10:00,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 01:10:01,197:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2022-11-18 01:15:32,919:INFO:PyCaret RegressionExperiment
2022-11-18 01:15:32,919:INFO:Logging name: reg-default-name
2022-11-18 01:15:32,919:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 01:15:32,919:INFO:version 3.0.0.rc4
2022-11-18 01:15:32,919:INFO:Initializing setup()
2022-11-18 01:15:32,920:INFO:self.USI: 3836
2022-11-18 01:15:32,920:INFO:self.variable_keys: {'display_container', 'memory', 'X', 'USI', 'y_train', 'fold_groups_param', '_gpu_n_jobs_param', 'variable_keys', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'X_test', 'data', 'exp_name_log', 'pipeline', '_all_models_internal', '_ml_usecase', '_available_plots', 'idx', 'logging_param', 'gpu_param', '_all_models', 'transform_target_method_param', 'target_param', 'fold_generator', 'master_model_container', 'transform_target_param', 'exp_id', 'y', 'n_jobs_param', '_all_metrics', 'seed', 'X_train', 'y_test'}
2022-11-18 01:15:32,920:INFO:Checking environment
2022-11-18 01:15:32,920:INFO:python_version: 3.9.15
2022-11-18 01:15:32,920:INFO:python_build: ('main', 'Oct 12 2022 19:14:37')
2022-11-18 01:15:32,920:INFO:machine: x86_64
2022-11-18 01:15:32,920:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-18 01:15:32,920:INFO:Memory: svmem(total=16338788352, available=7300280320, percent=55.3, used=7439732736, free=715202560, active=3412000768, inactive=10593320960, buffers=514256896, cached=7669596160, shared=1247936512, slab=973975552)
2022-11-18 01:15:32,921:INFO:Physical Core: 4
2022-11-18 01:15:32,921:INFO:Logical Core: 8
2022-11-18 01:15:32,921:INFO:Checking libraries
2022-11-18 01:15:32,921:INFO:System:
2022-11-18 01:15:32,921:INFO:    python: 3.9.15 (main, Oct 12 2022, 19:14:37)  [GCC 11.2.0]
2022-11-18 01:15:32,921:INFO:executable: /home/gfragi/PycharmProjects/py_regression/reg_pycaret/bin/python
2022-11-18 01:15:32,921:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-18 01:15:32,921:INFO:PyCaret required dependencies:
2022-11-18 01:15:32,921:INFO:                 pip: 22.0.4
2022-11-18 01:15:32,921:INFO:          setuptools: 58.1.0
2022-11-18 01:15:32,921:INFO:             pycaret: 3.0.0rc4
2022-11-18 01:15:32,921:INFO:             IPython: 8.6.0
2022-11-18 01:15:32,921:INFO:          ipywidgets: 8.0.2
2022-11-18 01:15:32,921:INFO:                tqdm: 4.64.1
2022-11-18 01:15:32,921:INFO:               numpy: 1.22.4
2022-11-18 01:15:32,921:INFO:              pandas: 1.4.4
2022-11-18 01:15:32,921:INFO:              jinja2: 3.1.2
2022-11-18 01:15:32,921:INFO:               scipy: 1.8.1
2022-11-18 01:15:32,921:INFO:              joblib: 1.2.0
2022-11-18 01:15:32,921:INFO:             sklearn: 1.1.3
2022-11-18 01:15:32,921:INFO:                pyod: 1.0.6
2022-11-18 01:15:32,921:INFO:            imblearn: 0.9.1
2022-11-18 01:15:32,921:INFO:   category_encoders: 2.5.1.post0
2022-11-18 01:15:32,921:INFO:            lightgbm: 3.3.3
2022-11-18 01:15:32,921:INFO:               numba: 0.55.2
2022-11-18 01:15:32,921:INFO:            requests: 2.28.1
2022-11-18 01:15:32,921:INFO:          matplotlib: 3.6.2
2022-11-18 01:15:32,921:INFO:          scikitplot: 0.3.7
2022-11-18 01:15:32,921:INFO:         yellowbrick: 1.5
2022-11-18 01:15:32,921:INFO:              plotly: 5.11.0
2022-11-18 01:15:32,921:INFO:             kaleido: 0.2.1
2022-11-18 01:15:32,921:INFO:         statsmodels: 0.13.5
2022-11-18 01:15:32,921:INFO:              sktime: 0.13.4
2022-11-18 01:15:32,921:INFO:               tbats: 1.1.1
2022-11-18 01:15:32,921:INFO:            pmdarima: 1.8.5
2022-11-18 01:15:32,921:INFO:              psutil: 5.9.4
2022-11-18 01:15:32,921:INFO:PyCaret optional dependencies:
2022-11-18 01:15:32,923:INFO:                shap: Not installed
2022-11-18 01:15:32,924:INFO:           interpret: Not installed
2022-11-18 01:15:32,924:INFO:                umap: Not installed
2022-11-18 01:15:32,924:INFO:    pandas_profiling: Not installed
2022-11-18 01:15:32,924:INFO:  explainerdashboard: Not installed
2022-11-18 01:15:32,924:INFO:             autoviz: Not installed
2022-11-18 01:15:32,924:INFO:           fairlearn: Not installed
2022-11-18 01:15:32,924:INFO:             xgboost: Not installed
2022-11-18 01:15:32,924:INFO:            catboost: Not installed
2022-11-18 01:15:32,924:INFO:              kmodes: Not installed
2022-11-18 01:15:32,924:INFO:             mlxtend: Not installed
2022-11-18 01:15:32,924:INFO:       statsforecast: Not installed
2022-11-18 01:15:32,924:INFO:        tune_sklearn: Not installed
2022-11-18 01:15:32,924:INFO:                 ray: Not installed
2022-11-18 01:15:32,924:INFO:            hyperopt: Not installed
2022-11-18 01:15:32,924:INFO:              optuna: Not installed
2022-11-18 01:15:32,924:INFO:               skopt: Not installed
2022-11-18 01:15:32,924:INFO:              mlflow: Not installed
2022-11-18 01:15:32,924:INFO:              gradio: Not installed
2022-11-18 01:15:32,924:INFO:             fastapi: Not installed
2022-11-18 01:15:32,924:INFO:             uvicorn: Not installed
2022-11-18 01:15:32,924:INFO:              m2cgen: Not installed
2022-11-18 01:15:32,924:INFO:           evidently: Not installed
2022-11-18 01:15:32,924:INFO:                nltk: Not installed
2022-11-18 01:15:32,924:INFO:            pyLDAvis: Not installed
2022-11-18 01:15:32,924:INFO:              gensim: Not installed
2022-11-18 01:15:32,924:INFO:               spacy: Not installed
2022-11-18 01:15:32,924:INFO:           wordcloud: Not installed
2022-11-18 01:15:32,924:INFO:            textblob: Not installed
2022-11-18 01:15:32,924:INFO:               fugue: Not installed
2022-11-18 01:15:32,924:INFO:           streamlit: Not installed
2022-11-18 01:15:32,925:INFO:             prophet: Not installed
2022-11-18 01:15:32,925:INFO:None
2022-11-18 01:15:32,925:INFO:Set up data.
2022-11-18 01:21:52,556:INFO:PyCaret RegressionExperiment
2022-11-18 01:21:52,556:INFO:Logging name: reg-default-name
2022-11-18 01:21:52,556:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 01:21:52,556:INFO:version 3.0.0.rc4
2022-11-18 01:21:52,556:INFO:Initializing setup()
2022-11-18 01:21:52,557:INFO:self.USI: c043
2022-11-18 01:21:52,557:INFO:self.variable_keys: {'display_container', 'memory', 'X', 'USI', 'y_train', 'fold_groups_param', '_gpu_n_jobs_param', 'variable_keys', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'X_test', 'data', 'exp_name_log', 'pipeline', '_all_models_internal', '_ml_usecase', '_available_plots', 'idx', 'logging_param', 'gpu_param', '_all_models', 'transform_target_method_param', 'target_param', 'fold_generator', 'master_model_container', 'transform_target_param', 'exp_id', 'y', 'n_jobs_param', '_all_metrics', 'seed', 'X_train', 'y_test'}
2022-11-18 01:21:52,557:INFO:Checking environment
2022-11-18 01:21:52,557:INFO:python_version: 3.9.15
2022-11-18 01:21:52,557:INFO:python_build: ('main', 'Oct 12 2022 19:14:37')
2022-11-18 01:21:52,557:INFO:machine: x86_64
2022-11-18 01:21:52,557:INFO:platform: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-18 01:21:52,557:INFO:Memory: svmem(total=16338788352, available=6878523392, percent=57.9, used=7883993088, free=618078208, active=3373309952, inactive=10731245568, buffers=509198336, cached=7327518720, shared=1225433088, slab=972070912)
2022-11-18 01:21:52,557:INFO:Physical Core: 4
2022-11-18 01:21:52,557:INFO:Logical Core: 8
2022-11-18 01:21:52,557:INFO:Checking libraries
2022-11-18 01:21:52,557:INFO:System:
2022-11-18 01:21:52,557:INFO:    python: 3.9.15 (main, Oct 12 2022, 19:14:37)  [GCC 11.2.0]
2022-11-18 01:21:52,557:INFO:executable: /home/gfragi/PycharmProjects/py_regression/reg_pycaret/bin/python
2022-11-18 01:21:52,557:INFO:   machine: Linux-5.15.0-52-generic-x86_64-with-glibc2.35
2022-11-18 01:21:52,557:INFO:PyCaret required dependencies:
2022-11-18 01:21:52,558:INFO:                 pip: 22.0.4
2022-11-18 01:21:52,558:INFO:          setuptools: 58.1.0
2022-11-18 01:21:52,558:INFO:             pycaret: 3.0.0rc4
2022-11-18 01:21:52,558:INFO:             IPython: 8.6.0
2022-11-18 01:21:52,558:INFO:          ipywidgets: 8.0.2
2022-11-18 01:21:52,558:INFO:                tqdm: 4.64.1
2022-11-18 01:21:52,558:INFO:               numpy: 1.22.4
2022-11-18 01:21:52,558:INFO:              pandas: 1.4.4
2022-11-18 01:21:52,558:INFO:              jinja2: 3.1.2
2022-11-18 01:21:52,558:INFO:               scipy: 1.8.1
2022-11-18 01:21:52,558:INFO:              joblib: 1.2.0
2022-11-18 01:21:52,558:INFO:             sklearn: 1.1.3
2022-11-18 01:21:52,558:INFO:                pyod: 1.0.6
2022-11-18 01:21:52,558:INFO:            imblearn: 0.9.1
2022-11-18 01:21:52,558:INFO:   category_encoders: 2.5.1.post0
2022-11-18 01:21:52,558:INFO:            lightgbm: 3.3.3
2022-11-18 01:21:52,558:INFO:               numba: 0.55.2
2022-11-18 01:21:52,558:INFO:            requests: 2.28.1
2022-11-18 01:21:52,558:INFO:          matplotlib: 3.6.2
2022-11-18 01:21:52,558:INFO:          scikitplot: 0.3.7
2022-11-18 01:21:52,558:INFO:         yellowbrick: 1.5
2022-11-18 01:21:52,558:INFO:              plotly: 5.11.0
2022-11-18 01:21:52,558:INFO:             kaleido: 0.2.1
2022-11-18 01:21:52,558:INFO:         statsmodels: 0.13.5
2022-11-18 01:21:52,558:INFO:              sktime: 0.13.4
2022-11-18 01:21:52,558:INFO:               tbats: 1.1.1
2022-11-18 01:21:52,558:INFO:            pmdarima: 1.8.5
2022-11-18 01:21:52,559:INFO:              psutil: 5.9.4
2022-11-18 01:21:52,559:INFO:PyCaret optional dependencies:
2022-11-18 01:21:52,559:INFO:                shap: Not installed
2022-11-18 01:21:52,559:INFO:           interpret: Not installed
2022-11-18 01:21:52,559:INFO:                umap: Not installed
2022-11-18 01:21:52,559:INFO:    pandas_profiling: Not installed
2022-11-18 01:21:52,559:INFO:  explainerdashboard: Not installed
2022-11-18 01:21:52,559:INFO:             autoviz: Not installed
2022-11-18 01:21:52,559:INFO:           fairlearn: Not installed
2022-11-18 01:21:52,559:INFO:             xgboost: Not installed
2022-11-18 01:21:52,559:INFO:            catboost: Not installed
2022-11-18 01:21:52,559:INFO:              kmodes: Not installed
2022-11-18 01:21:52,559:INFO:             mlxtend: Not installed
2022-11-18 01:21:52,559:INFO:       statsforecast: Not installed
2022-11-18 01:21:52,559:INFO:        tune_sklearn: Not installed
2022-11-18 01:21:52,559:INFO:                 ray: Not installed
2022-11-18 01:21:52,559:INFO:            hyperopt: Not installed
2022-11-18 01:21:52,559:INFO:              optuna: Not installed
2022-11-18 01:21:52,559:INFO:               skopt: Not installed
2022-11-18 01:21:52,559:INFO:              mlflow: Not installed
2022-11-18 01:21:52,559:INFO:              gradio: Not installed
2022-11-18 01:21:52,559:INFO:             fastapi: Not installed
2022-11-18 01:21:52,559:INFO:             uvicorn: Not installed
2022-11-18 01:21:52,559:INFO:              m2cgen: Not installed
2022-11-18 01:21:52,560:INFO:           evidently: Not installed
2022-11-18 01:21:52,560:INFO:                nltk: Not installed
2022-11-18 01:21:52,560:INFO:            pyLDAvis: Not installed
2022-11-18 01:21:52,560:INFO:              gensim: Not installed
2022-11-18 01:21:52,560:INFO:               spacy: Not installed
2022-11-18 01:21:52,560:INFO:           wordcloud: Not installed
2022-11-18 01:21:52,560:INFO:            textblob: Not installed
2022-11-18 01:21:52,560:INFO:               fugue: Not installed
2022-11-18 01:21:52,560:INFO:           streamlit: Not installed
2022-11-18 01:21:52,560:INFO:             prophet: Not installed
2022-11-18 01:21:52,560:INFO:None
2022-11-18 01:21:52,560:INFO:Set up data.
2022-11-18 01:21:52,568:INFO:Set up train/test split.
2022-11-18 01:21:52,574:INFO:Set up index.
2022-11-18 01:21:52,575:INFO:Set up folding strategy.
2022-11-18 01:21:52,575:INFO:Assigning column types.
2022-11-18 01:21:52,578:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 01:21:52,578:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,582:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,586:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,675:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,678:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,723:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,756:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 01:21:52,760:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,763:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,846:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,849:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:52,926:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 01:21:52,933:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 01:21:52,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,015:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,093:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 01:21:53,140:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,172:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,221:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,254:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,255:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 01:21:53,306:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,387:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 01:21:53,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,421:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 01:21:53,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:53,596:INFO:Preparing preprocessing pipeline...
2022-11-18 01:21:53,597:INFO:Set up simple imputation.
2022-11-18 01:21:53,605:INFO:Set up encoding of ordinal features.
2022-11-18 01:21:53,613:INFO:Set up encoding of categorical features.
2022-11-18 01:21:53,614:INFO:Set up variance threshold.
2022-11-18 01:21:53,614:INFO:Set up removing multicollinearity.
2022-11-18 01:21:53,614:INFO:Set up column transformation.
2022-11-18 01:21:53,614:INFO:Set up feature normalization.
2022-11-18 01:21:53,927:INFO:Finished creating preprocessing pipeline.
2022-11-18 01:21:53,943:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['CPU', 'RAM', 'STORAGE',
                                             'external_egress',
                                             'internal_egress', 'Term_Length'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Provider', 'Deployment Type',
                                             'Autoscaling', 'Instance_Type',
                                             'OS', 'Region', 'Scaling_to_zero',
                                             'AppS...
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[],
                                    transformer=RemoveMulticollinearity(threshold=0.95))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2022-11-18 01:21:53,943:INFO:Creating final display dataframe.
2022-11-18 01:21:54,712:INFO:Setup display_container:                     Description             Value
0                    Session id               123
1                        Target             Price
2                   Target type        Regression
3                    Data shape         (806, 23)
4              Train data shape         (564, 23)
5               Test data shape         (242, 23)
6              Ordinal features                 6
7              Numeric features                 6
8          Categorical features                11
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation          constant
13     Maximum one-hot encoding                 5
14              Encoding method              None
15       Low variance threshold                 0
16     Remove multicollinearity              True
17  Multicollinearity threshold              0.95
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22               Fold Generator             KFold
23                  Fold Number                10
24                     CPU Jobs                -1
25                      Use GPU             False
26               Log Experiment             False
27              Experiment Name  reg-default-name
28                          USI              c043
2022-11-18 01:21:54,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:54,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:54,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:54,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 01:21:54,913:INFO:setup() successfully completed in 2.36s...............
2022-11-18 01:23:10,661:INFO:Initializing compare_models()
2022-11-18 01:23:10,661:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2022-11-18 01:23:10,662:INFO:Checking exceptions
2022-11-18 01:23:10,664:INFO:Preparing display monitor
2022-11-18 01:23:10,694:INFO:Initializing Linear Regression
2022-11-18 01:23:10,694:INFO:Total runtime is 3.1073888142903646e-06 minutes
2022-11-18 01:23:10,697:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:10,698:INFO:Initializing create_model()
2022-11-18 01:23:10,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:10,698:INFO:Checking exceptions
2022-11-18 01:23:10,700:INFO:Importing libraries
2022-11-18 01:23:10,700:INFO:Copying training dataset
2022-11-18 01:23:10,702:INFO:Defining folds
2022-11-18 01:23:10,702:INFO:Declaring metric variables
2022-11-18 01:23:10,706:INFO:Importing untrained model
2022-11-18 01:23:10,710:INFO:Linear Regression Imported successfully
2022-11-18 01:23:10,717:INFO:Starting cross validation
2022-11-18 01:23:10,721:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:14,946:INFO:Calculating mean and std
2022-11-18 01:23:14,947:INFO:Creating metrics dataframe
2022-11-18 01:23:14,950:INFO:Uploading results into container
2022-11-18 01:23:14,951:INFO:Uploading model into container now
2022-11-18 01:23:14,951:INFO:master_model_container: 1
2022-11-18 01:23:14,951:INFO:display_container: 2
2022-11-18 01:23:14,952:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:23:14,952:INFO:create_model() successfully completed......................................
2022-11-18 01:23:15,054:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:15,054:INFO:Creating metrics dataframe
2022-11-18 01:23:15,062:INFO:Initializing Lasso Regression
2022-11-18 01:23:15,062:INFO:Total runtime is 0.0727983554204305 minutes
2022-11-18 01:23:15,065:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:15,065:INFO:Initializing create_model()
2022-11-18 01:23:15,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:15,066:INFO:Checking exceptions
2022-11-18 01:23:15,067:INFO:Importing libraries
2022-11-18 01:23:15,067:INFO:Copying training dataset
2022-11-18 01:23:15,071:INFO:Defining folds
2022-11-18 01:23:15,071:INFO:Declaring metric variables
2022-11-18 01:23:15,074:INFO:Importing untrained model
2022-11-18 01:23:15,077:INFO:Lasso Regression Imported successfully
2022-11-18 01:23:15,083:INFO:Starting cross validation
2022-11-18 01:23:15,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:15,628:INFO:Calculating mean and std
2022-11-18 01:23:15,630:INFO:Creating metrics dataframe
2022-11-18 01:23:15,632:INFO:Uploading results into container
2022-11-18 01:23:15,633:INFO:Uploading model into container now
2022-11-18 01:23:15,633:INFO:master_model_container: 2
2022-11-18 01:23:15,633:INFO:display_container: 2
2022-11-18 01:23:15,634:INFO:Lasso(random_state=123)
2022-11-18 01:23:15,634:INFO:create_model() successfully completed......................................
2022-11-18 01:23:15,719:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:15,720:INFO:Creating metrics dataframe
2022-11-18 01:23:15,728:INFO:Initializing Ridge Regression
2022-11-18 01:23:15,728:INFO:Total runtime is 0.08390017747879029 minutes
2022-11-18 01:23:15,731:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:15,731:INFO:Initializing create_model()
2022-11-18 01:23:15,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:15,732:INFO:Checking exceptions
2022-11-18 01:23:15,734:INFO:Importing libraries
2022-11-18 01:23:15,734:INFO:Copying training dataset
2022-11-18 01:23:15,737:INFO:Defining folds
2022-11-18 01:23:15,737:INFO:Declaring metric variables
2022-11-18 01:23:15,740:INFO:Importing untrained model
2022-11-18 01:23:15,743:INFO:Ridge Regression Imported successfully
2022-11-18 01:23:15,749:INFO:Starting cross validation
2022-11-18 01:23:15,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:15,995:INFO:Calculating mean and std
2022-11-18 01:23:15,997:INFO:Creating metrics dataframe
2022-11-18 01:23:15,999:INFO:Uploading results into container
2022-11-18 01:23:16,000:INFO:Uploading model into container now
2022-11-18 01:23:16,000:INFO:master_model_container: 3
2022-11-18 01:23:16,000:INFO:display_container: 2
2022-11-18 01:23:16,000:INFO:Ridge(random_state=123)
2022-11-18 01:23:16,000:INFO:create_model() successfully completed......................................
2022-11-18 01:23:16,088:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:16,088:INFO:Creating metrics dataframe
2022-11-18 01:23:16,096:INFO:Initializing Elastic Net
2022-11-18 01:23:16,096:INFO:Total runtime is 0.09002820253372193 minutes
2022-11-18 01:23:16,098:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:16,099:INFO:Initializing create_model()
2022-11-18 01:23:16,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:16,099:INFO:Checking exceptions
2022-11-18 01:23:16,101:INFO:Importing libraries
2022-11-18 01:23:16,101:INFO:Copying training dataset
2022-11-18 01:23:16,105:INFO:Defining folds
2022-11-18 01:23:16,105:INFO:Declaring metric variables
2022-11-18 01:23:16,108:INFO:Importing untrained model
2022-11-18 01:23:16,111:INFO:Elastic Net Imported successfully
2022-11-18 01:23:16,117:INFO:Starting cross validation
2022-11-18 01:23:16,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:16,364:INFO:Calculating mean and std
2022-11-18 01:23:16,366:INFO:Creating metrics dataframe
2022-11-18 01:23:16,368:INFO:Uploading results into container
2022-11-18 01:23:16,369:INFO:Uploading model into container now
2022-11-18 01:23:16,369:INFO:master_model_container: 4
2022-11-18 01:23:16,369:INFO:display_container: 2
2022-11-18 01:23:16,370:INFO:ElasticNet(random_state=123)
2022-11-18 01:23:16,370:INFO:create_model() successfully completed......................................
2022-11-18 01:23:16,460:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:16,460:INFO:Creating metrics dataframe
2022-11-18 01:23:16,469:INFO:Initializing Least Angle Regression
2022-11-18 01:23:16,470:INFO:Total runtime is 0.09625748793284099 minutes
2022-11-18 01:23:16,474:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:16,475:INFO:Initializing create_model()
2022-11-18 01:23:16,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:16,475:INFO:Checking exceptions
2022-11-18 01:23:16,477:INFO:Importing libraries
2022-11-18 01:23:16,477:INFO:Copying training dataset
2022-11-18 01:23:16,482:INFO:Defining folds
2022-11-18 01:23:16,482:INFO:Declaring metric variables
2022-11-18 01:23:16,486:INFO:Importing untrained model
2022-11-18 01:23:16,490:INFO:Least Angle Regression Imported successfully
2022-11-18 01:23:16,500:INFO:Starting cross validation
2022-11-18 01:23:16,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:16,607:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,612:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,623:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,628:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.346e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,628:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,629:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.270e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,630:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.015e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,630:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.850e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,631:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.064e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,631:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.260e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,631:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.418e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,632:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.603e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,632:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.922e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,634:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,638:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.951e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,639:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.590e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,640:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.082e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,641:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.095e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,641:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.983e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,642:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.279e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,642:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.491e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,642:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.421e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,653:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,658:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,664:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,668:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.995e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,669:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.425e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,669:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.617e-06, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,670:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.126e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:23:16,731:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,732:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:16,762:INFO:Calculating mean and std
2022-11-18 01:23:16,763:INFO:Creating metrics dataframe
2022-11-18 01:23:16,766:INFO:Uploading results into container
2022-11-18 01:23:16,766:INFO:Uploading model into container now
2022-11-18 01:23:16,766:INFO:master_model_container: 5
2022-11-18 01:23:16,766:INFO:display_container: 2
2022-11-18 01:23:16,767:INFO:Lars(random_state=123)
2022-11-18 01:23:16,767:INFO:create_model() successfully completed......................................
2022-11-18 01:23:16,852:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:16,852:INFO:Creating metrics dataframe
2022-11-18 01:23:16,861:INFO:Initializing Lasso Least Angle Regression
2022-11-18 01:23:16,861:INFO:Total runtime is 0.10277609030405681 minutes
2022-11-18 01:23:16,863:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:16,864:INFO:Initializing create_model()
2022-11-18 01:23:16,864:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:16,864:INFO:Checking exceptions
2022-11-18 01:23:16,865:INFO:Importing libraries
2022-11-18 01:23:16,865:INFO:Copying training dataset
2022-11-18 01:23:16,869:INFO:Defining folds
2022-11-18 01:23:16,869:INFO:Declaring metric variables
2022-11-18 01:23:16,872:INFO:Importing untrained model
2022-11-18 01:23:16,875:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 01:23:16,883:INFO:Starting cross validation
2022-11-18 01:23:16,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:16,973:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:16,992:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:16,997:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,008:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,013:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,034:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,042:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,043:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,103:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,115:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:23:17,144:INFO:Calculating mean and std
2022-11-18 01:23:17,145:INFO:Creating metrics dataframe
2022-11-18 01:23:17,148:INFO:Uploading results into container
2022-11-18 01:23:17,148:INFO:Uploading model into container now
2022-11-18 01:23:17,148:INFO:master_model_container: 6
2022-11-18 01:23:17,148:INFO:display_container: 2
2022-11-18 01:23:17,149:INFO:LassoLars(random_state=123)
2022-11-18 01:23:17,149:INFO:create_model() successfully completed......................................
2022-11-18 01:23:17,235:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:17,235:INFO:Creating metrics dataframe
2022-11-18 01:23:17,244:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 01:23:17,244:INFO:Total runtime is 0.10916345516840617 minutes
2022-11-18 01:23:17,247:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:17,247:INFO:Initializing create_model()
2022-11-18 01:23:17,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:17,247:INFO:Checking exceptions
2022-11-18 01:23:17,249:INFO:Importing libraries
2022-11-18 01:23:17,249:INFO:Copying training dataset
2022-11-18 01:23:17,252:INFO:Defining folds
2022-11-18 01:23:17,252:INFO:Declaring metric variables
2022-11-18 01:23:17,256:INFO:Importing untrained model
2022-11-18 01:23:17,259:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 01:23:17,265:INFO:Starting cross validation
2022-11-18 01:23:17,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:17,366:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,374:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,382:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,385:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,396:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,402:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,415:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,420:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,487:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,494:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:23:17,542:INFO:Calculating mean and std
2022-11-18 01:23:17,544:INFO:Creating metrics dataframe
2022-11-18 01:23:17,547:INFO:Uploading results into container
2022-11-18 01:23:17,548:INFO:Uploading model into container now
2022-11-18 01:23:17,548:INFO:master_model_container: 7
2022-11-18 01:23:17,549:INFO:display_container: 2
2022-11-18 01:23:17,549:INFO:OrthogonalMatchingPursuit()
2022-11-18 01:23:17,549:INFO:create_model() successfully completed......................................
2022-11-18 01:23:17,636:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:17,636:INFO:Creating metrics dataframe
2022-11-18 01:23:17,647:INFO:Initializing Bayesian Ridge
2022-11-18 01:23:17,647:INFO:Total runtime is 0.11588754256566365 minutes
2022-11-18 01:23:17,650:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:17,650:INFO:Initializing create_model()
2022-11-18 01:23:17,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:17,651:INFO:Checking exceptions
2022-11-18 01:23:17,652:INFO:Importing libraries
2022-11-18 01:23:17,652:INFO:Copying training dataset
2022-11-18 01:23:17,657:INFO:Defining folds
2022-11-18 01:23:17,657:INFO:Declaring metric variables
2022-11-18 01:23:17,660:INFO:Importing untrained model
2022-11-18 01:23:17,664:INFO:Bayesian Ridge Imported successfully
2022-11-18 01:23:17,669:INFO:Starting cross validation
2022-11-18 01:23:17,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:17,932:INFO:Calculating mean and std
2022-11-18 01:23:17,934:INFO:Creating metrics dataframe
2022-11-18 01:23:17,936:INFO:Uploading results into container
2022-11-18 01:23:17,937:INFO:Uploading model into container now
2022-11-18 01:23:17,937:INFO:master_model_container: 8
2022-11-18 01:23:17,937:INFO:display_container: 2
2022-11-18 01:23:17,938:INFO:BayesianRidge()
2022-11-18 01:23:17,938:INFO:create_model() successfully completed......................................
2022-11-18 01:23:18,026:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:18,026:INFO:Creating metrics dataframe
2022-11-18 01:23:18,033:INFO:Initializing Passive Aggressive Regressor
2022-11-18 01:23:18,034:INFO:Total runtime is 0.1223218043645223 minutes
2022-11-18 01:23:18,036:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:18,036:INFO:Initializing create_model()
2022-11-18 01:23:18,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:18,037:INFO:Checking exceptions
2022-11-18 01:23:18,039:INFO:Importing libraries
2022-11-18 01:23:18,039:INFO:Copying training dataset
2022-11-18 01:23:18,043:INFO:Defining folds
2022-11-18 01:23:18,044:INFO:Declaring metric variables
2022-11-18 01:23:18,047:INFO:Importing untrained model
2022-11-18 01:23:18,051:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 01:23:18,058:INFO:Starting cross validation
2022-11-18 01:23:18,061:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:18,315:INFO:Calculating mean and std
2022-11-18 01:23:18,316:INFO:Creating metrics dataframe
2022-11-18 01:23:18,319:INFO:Uploading results into container
2022-11-18 01:23:18,319:INFO:Uploading model into container now
2022-11-18 01:23:18,320:INFO:master_model_container: 9
2022-11-18 01:23:18,320:INFO:display_container: 2
2022-11-18 01:23:18,320:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 01:23:18,320:INFO:create_model() successfully completed......................................
2022-11-18 01:23:18,408:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:18,408:INFO:Creating metrics dataframe
2022-11-18 01:23:18,416:INFO:Initializing Huber Regressor
2022-11-18 01:23:18,416:INFO:Total runtime is 0.1286951224009196 minutes
2022-11-18 01:23:18,418:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:18,419:INFO:Initializing create_model()
2022-11-18 01:23:18,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:18,419:INFO:Checking exceptions
2022-11-18 01:23:18,421:INFO:Importing libraries
2022-11-18 01:23:18,421:INFO:Copying training dataset
2022-11-18 01:23:18,425:INFO:Defining folds
2022-11-18 01:23:18,425:INFO:Declaring metric variables
2022-11-18 01:23:18,428:INFO:Importing untrained model
2022-11-18 01:23:18,431:INFO:Huber Regressor Imported successfully
2022-11-18 01:23:18,436:INFO:Starting cross validation
2022-11-18 01:23:18,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:18,714:INFO:Calculating mean and std
2022-11-18 01:23:18,715:INFO:Creating metrics dataframe
2022-11-18 01:23:18,718:INFO:Uploading results into container
2022-11-18 01:23:18,718:INFO:Uploading model into container now
2022-11-18 01:23:18,719:INFO:master_model_container: 10
2022-11-18 01:23:18,719:INFO:display_container: 2
2022-11-18 01:23:18,719:INFO:HuberRegressor()
2022-11-18 01:23:18,719:INFO:create_model() successfully completed......................................
2022-11-18 01:23:18,807:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:18,807:INFO:Creating metrics dataframe
2022-11-18 01:23:18,815:INFO:Initializing K Neighbors Regressor
2022-11-18 01:23:18,815:INFO:Total runtime is 0.1353481928507487 minutes
2022-11-18 01:23:18,818:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:18,818:INFO:Initializing create_model()
2022-11-18 01:23:18,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:18,818:INFO:Checking exceptions
2022-11-18 01:23:18,820:INFO:Importing libraries
2022-11-18 01:23:18,821:INFO:Copying training dataset
2022-11-18 01:23:18,825:INFO:Defining folds
2022-11-18 01:23:18,825:INFO:Declaring metric variables
2022-11-18 01:23:18,828:INFO:Importing untrained model
2022-11-18 01:23:18,831:INFO:K Neighbors Regressor Imported successfully
2022-11-18 01:23:18,836:INFO:Starting cross validation
2022-11-18 01:23:18,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:19,139:INFO:Calculating mean and std
2022-11-18 01:23:19,141:INFO:Creating metrics dataframe
2022-11-18 01:23:19,145:INFO:Uploading results into container
2022-11-18 01:23:19,146:INFO:Uploading model into container now
2022-11-18 01:23:19,146:INFO:master_model_container: 11
2022-11-18 01:23:19,146:INFO:display_container: 2
2022-11-18 01:23:19,146:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 01:23:19,147:INFO:create_model() successfully completed......................................
2022-11-18 01:23:19,234:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:19,234:INFO:Creating metrics dataframe
2022-11-18 01:23:19,243:INFO:Initializing Decision Tree Regressor
2022-11-18 01:23:19,243:INFO:Total runtime is 0.14247893889745078 minutes
2022-11-18 01:23:19,246:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:19,246:INFO:Initializing create_model()
2022-11-18 01:23:19,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:19,246:INFO:Checking exceptions
2022-11-18 01:23:19,248:INFO:Importing libraries
2022-11-18 01:23:19,248:INFO:Copying training dataset
2022-11-18 01:23:19,251:INFO:Defining folds
2022-11-18 01:23:19,251:INFO:Declaring metric variables
2022-11-18 01:23:19,254:INFO:Importing untrained model
2022-11-18 01:23:19,258:INFO:Decision Tree Regressor Imported successfully
2022-11-18 01:23:19,267:INFO:Starting cross validation
2022-11-18 01:23:19,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:19,526:INFO:Calculating mean and std
2022-11-18 01:23:19,527:INFO:Creating metrics dataframe
2022-11-18 01:23:19,530:INFO:Uploading results into container
2022-11-18 01:23:19,530:INFO:Uploading model into container now
2022-11-18 01:23:19,530:INFO:master_model_container: 12
2022-11-18 01:23:19,530:INFO:display_container: 2
2022-11-18 01:23:19,531:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 01:23:19,531:INFO:create_model() successfully completed......................................
2022-11-18 01:23:19,618:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:19,618:INFO:Creating metrics dataframe
2022-11-18 01:23:19,627:INFO:Initializing Random Forest Regressor
2022-11-18 01:23:19,627:INFO:Total runtime is 0.14888357321421306 minutes
2022-11-18 01:23:19,630:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:19,630:INFO:Initializing create_model()
2022-11-18 01:23:19,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:19,630:INFO:Checking exceptions
2022-11-18 01:23:19,632:INFO:Importing libraries
2022-11-18 01:23:19,632:INFO:Copying training dataset
2022-11-18 01:23:19,635:INFO:Defining folds
2022-11-18 01:23:19,636:INFO:Declaring metric variables
2022-11-18 01:23:19,639:INFO:Importing untrained model
2022-11-18 01:23:19,643:INFO:Random Forest Regressor Imported successfully
2022-11-18 01:23:19,649:INFO:Starting cross validation
2022-11-18 01:23:19,650:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:20,448:INFO:Calculating mean and std
2022-11-18 01:23:20,450:INFO:Creating metrics dataframe
2022-11-18 01:23:20,453:INFO:Uploading results into container
2022-11-18 01:23:20,453:INFO:Uploading model into container now
2022-11-18 01:23:20,454:INFO:master_model_container: 13
2022-11-18 01:23:20,454:INFO:display_container: 2
2022-11-18 01:23:20,454:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:23:20,455:INFO:create_model() successfully completed......................................
2022-11-18 01:23:20,549:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:20,550:INFO:Creating metrics dataframe
2022-11-18 01:23:20,564:INFO:Initializing Extra Trees Regressor
2022-11-18 01:23:20,565:INFO:Total runtime is 0.1645052433013916 minutes
2022-11-18 01:23:20,568:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:20,569:INFO:Initializing create_model()
2022-11-18 01:23:20,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:20,569:INFO:Checking exceptions
2022-11-18 01:23:20,572:INFO:Importing libraries
2022-11-18 01:23:20,572:INFO:Copying training dataset
2022-11-18 01:23:20,576:INFO:Defining folds
2022-11-18 01:23:20,576:INFO:Declaring metric variables
2022-11-18 01:23:20,580:INFO:Importing untrained model
2022-11-18 01:23:20,584:INFO:Extra Trees Regressor Imported successfully
2022-11-18 01:23:20,592:INFO:Starting cross validation
2022-11-18 01:23:20,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:21,324:INFO:Calculating mean and std
2022-11-18 01:23:21,326:INFO:Creating metrics dataframe
2022-11-18 01:23:21,328:INFO:Uploading results into container
2022-11-18 01:23:21,329:INFO:Uploading model into container now
2022-11-18 01:23:21,329:INFO:master_model_container: 14
2022-11-18 01:23:21,329:INFO:display_container: 2
2022-11-18 01:23:21,330:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:23:21,330:INFO:create_model() successfully completed......................................
2022-11-18 01:23:21,434:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:21,434:INFO:Creating metrics dataframe
2022-11-18 01:23:21,458:INFO:Initializing AdaBoost Regressor
2022-11-18 01:23:21,459:INFO:Total runtime is 0.1794087290763855 minutes
2022-11-18 01:23:21,464:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:21,465:INFO:Initializing create_model()
2022-11-18 01:23:21,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:21,465:INFO:Checking exceptions
2022-11-18 01:23:21,491:INFO:Importing libraries
2022-11-18 01:23:21,491:INFO:Copying training dataset
2022-11-18 01:23:21,515:INFO:Defining folds
2022-11-18 01:23:21,516:INFO:Declaring metric variables
2022-11-18 01:23:21,522:INFO:Importing untrained model
2022-11-18 01:23:21,529:INFO:AdaBoost Regressor Imported successfully
2022-11-18 01:23:21,539:INFO:Starting cross validation
2022-11-18 01:23:21,542:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:22,143:INFO:Calculating mean and std
2022-11-18 01:23:22,145:INFO:Creating metrics dataframe
2022-11-18 01:23:22,148:INFO:Uploading results into container
2022-11-18 01:23:22,149:INFO:Uploading model into container now
2022-11-18 01:23:22,150:INFO:master_model_container: 15
2022-11-18 01:23:22,150:INFO:display_container: 2
2022-11-18 01:23:22,150:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 01:23:22,150:INFO:create_model() successfully completed......................................
2022-11-18 01:23:22,264:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:22,264:INFO:Creating metrics dataframe
2022-11-18 01:23:22,280:INFO:Initializing Gradient Boosting Regressor
2022-11-18 01:23:22,281:INFO:Total runtime is 0.19310710430145264 minutes
2022-11-18 01:23:22,285:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:22,285:INFO:Initializing create_model()
2022-11-18 01:23:22,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:22,286:INFO:Checking exceptions
2022-11-18 01:23:22,288:INFO:Importing libraries
2022-11-18 01:23:22,288:INFO:Copying training dataset
2022-11-18 01:23:22,293:INFO:Defining folds
2022-11-18 01:23:22,293:INFO:Declaring metric variables
2022-11-18 01:23:22,297:INFO:Importing untrained model
2022-11-18 01:23:22,303:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 01:23:22,313:INFO:Starting cross validation
2022-11-18 01:23:22,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:22,758:INFO:Calculating mean and std
2022-11-18 01:23:22,759:INFO:Creating metrics dataframe
2022-11-18 01:23:22,762:INFO:Uploading results into container
2022-11-18 01:23:22,763:INFO:Uploading model into container now
2022-11-18 01:23:22,763:INFO:master_model_container: 16
2022-11-18 01:23:22,763:INFO:display_container: 2
2022-11-18 01:23:22,764:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 01:23:22,764:INFO:create_model() successfully completed......................................
2022-11-18 01:23:22,854:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:22,854:INFO:Creating metrics dataframe
2022-11-18 01:23:22,864:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 01:23:22,864:INFO:Total runtime is 0.2028334895769755 minutes
2022-11-18 01:23:22,867:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:22,867:INFO:Initializing create_model()
2022-11-18 01:23:22,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:22,867:INFO:Checking exceptions
2022-11-18 01:23:22,869:INFO:Importing libraries
2022-11-18 01:23:22,869:INFO:Copying training dataset
2022-11-18 01:23:22,873:INFO:Defining folds
2022-11-18 01:23:22,873:INFO:Declaring metric variables
2022-11-18 01:23:22,876:INFO:Importing untrained model
2022-11-18 01:23:22,879:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 01:23:22,884:INFO:Starting cross validation
2022-11-18 01:23:22,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:23,201:INFO:Calculating mean and std
2022-11-18 01:23:23,202:INFO:Creating metrics dataframe
2022-11-18 01:23:23,205:INFO:Uploading results into container
2022-11-18 01:23:23,205:INFO:Uploading model into container now
2022-11-18 01:23:23,206:INFO:master_model_container: 17
2022-11-18 01:23:23,206:INFO:display_container: 2
2022-11-18 01:23:23,206:INFO:LGBMRegressor(random_state=123)
2022-11-18 01:23:23,206:INFO:create_model() successfully completed......................................
2022-11-18 01:23:23,294:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:23,294:INFO:Creating metrics dataframe
2022-11-18 01:23:23,304:INFO:Initializing Dummy Regressor
2022-11-18 01:23:23,304:INFO:Total runtime is 0.21016079187393188 minutes
2022-11-18 01:23:23,307:INFO:SubProcess create_model() called ==================================
2022-11-18 01:23:23,307:INFO:Initializing create_model()
2022-11-18 01:23:23,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46835e20>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:23,307:INFO:Checking exceptions
2022-11-18 01:23:23,309:INFO:Importing libraries
2022-11-18 01:23:23,309:INFO:Copying training dataset
2022-11-18 01:23:23,312:INFO:Defining folds
2022-11-18 01:23:23,313:INFO:Declaring metric variables
2022-11-18 01:23:23,315:INFO:Importing untrained model
2022-11-18 01:23:23,319:INFO:Dummy Regressor Imported successfully
2022-11-18 01:23:23,324:INFO:Starting cross validation
2022-11-18 01:23:23,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:23:23,576:INFO:Calculating mean and std
2022-11-18 01:23:23,577:INFO:Creating metrics dataframe
2022-11-18 01:23:23,580:INFO:Uploading results into container
2022-11-18 01:23:23,581:INFO:Uploading model into container now
2022-11-18 01:23:23,581:INFO:master_model_container: 18
2022-11-18 01:23:23,581:INFO:display_container: 2
2022-11-18 01:23:23,581:INFO:DummyRegressor()
2022-11-18 01:23:23,581:INFO:create_model() successfully completed......................................
2022-11-18 01:23:23,668:INFO:SubProcess create_model() end ==================================
2022-11-18 01:23:23,668:INFO:Creating metrics dataframe
2022-11-18 01:23:23,690:INFO:Initializing create_model()
2022-11-18 01:23:23,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:23,690:INFO:Checking exceptions
2022-11-18 01:23:23,693:INFO:Importing libraries
2022-11-18 01:23:23,693:INFO:Copying training dataset
2022-11-18 01:23:23,696:INFO:Defining folds
2022-11-18 01:23:23,696:INFO:Declaring metric variables
2022-11-18 01:23:23,696:INFO:Importing untrained model
2022-11-18 01:23:23,696:INFO:Declaring custom model
2022-11-18 01:23:23,697:INFO:Extra Trees Regressor Imported successfully
2022-11-18 01:23:23,698:INFO:Cross validation set to False
2022-11-18 01:23:23,698:INFO:Fitting Model
2022-11-18 01:23:23,918:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:23:23,919:INFO:create_model() successfully completed......................................
2022-11-18 01:23:24,020:INFO:Initializing create_model()
2022-11-18 01:23:24,020:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:24,020:INFO:Checking exceptions
2022-11-18 01:23:24,024:INFO:Importing libraries
2022-11-18 01:23:24,024:INFO:Copying training dataset
2022-11-18 01:23:24,026:INFO:Defining folds
2022-11-18 01:23:24,026:INFO:Declaring metric variables
2022-11-18 01:23:24,026:INFO:Importing untrained model
2022-11-18 01:23:24,026:INFO:Declaring custom model
2022-11-18 01:23:24,027:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 01:23:24,028:INFO:Cross validation set to False
2022-11-18 01:23:24,028:INFO:Fitting Model
2022-11-18 01:23:24,131:INFO:LGBMRegressor(random_state=123)
2022-11-18 01:23:24,132:INFO:create_model() successfully completed......................................
2022-11-18 01:23:24,224:INFO:Initializing create_model()
2022-11-18 01:23:24,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:23:24,224:INFO:Checking exceptions
2022-11-18 01:23:24,227:INFO:Importing libraries
2022-11-18 01:23:24,227:INFO:Copying training dataset
2022-11-18 01:23:24,229:INFO:Defining folds
2022-11-18 01:23:24,229:INFO:Declaring metric variables
2022-11-18 01:23:24,229:INFO:Importing untrained model
2022-11-18 01:23:24,229:INFO:Declaring custom model
2022-11-18 01:23:24,230:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 01:23:24,231:INFO:Cross validation set to False
2022-11-18 01:23:24,231:INFO:Fitting Model
2022-11-18 01:23:24,337:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 01:23:24,337:INFO:create_model() successfully completed......................................
2022-11-18 01:23:24,444:INFO:master_model_container: 18
2022-11-18 01:23:24,444:INFO:display_container: 2
2022-11-18 01:23:24,445:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), LGBMRegressor(random_state=123), GradientBoostingRegressor(random_state=123)]
2022-11-18 01:23:24,445:INFO:compare_models() successfully completed......................................
2022-11-18 01:25:01,581:INFO:Initializing compare_models()
2022-11-18 01:25:01,581:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2022-11-18 01:25:01,582:INFO:Checking exceptions
2022-11-18 01:25:01,584:INFO:Preparing display monitor
2022-11-18 01:25:01,615:INFO:Initializing Linear Regression
2022-11-18 01:25:01,615:INFO:Total runtime is 3.4769376118977866e-06 minutes
2022-11-18 01:25:01,618:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:01,618:INFO:Initializing create_model()
2022-11-18 01:25:01,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:01,619:INFO:Checking exceptions
2022-11-18 01:25:01,620:INFO:Importing libraries
2022-11-18 01:25:01,620:INFO:Copying training dataset
2022-11-18 01:25:01,623:INFO:Defining folds
2022-11-18 01:25:01,623:INFO:Declaring metric variables
2022-11-18 01:25:01,627:INFO:Importing untrained model
2022-11-18 01:25:01,631:INFO:Linear Regression Imported successfully
2022-11-18 01:25:01,637:INFO:Starting cross validation
2022-11-18 01:25:01,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:01,898:INFO:Calculating mean and std
2022-11-18 01:25:01,899:INFO:Creating metrics dataframe
2022-11-18 01:25:01,901:INFO:Uploading results into container
2022-11-18 01:25:01,901:INFO:Uploading model into container now
2022-11-18 01:25:01,902:INFO:master_model_container: 19
2022-11-18 01:25:01,902:INFO:display_container: 3
2022-11-18 01:25:01,902:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:25:01,902:INFO:create_model() successfully completed......................................
2022-11-18 01:25:01,989:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:01,990:INFO:Creating metrics dataframe
2022-11-18 01:25:01,996:INFO:Initializing Lasso Regression
2022-11-18 01:25:01,996:INFO:Total runtime is 0.00635163386662801 minutes
2022-11-18 01:25:02,000:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:02,000:INFO:Initializing create_model()
2022-11-18 01:25:02,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:02,000:INFO:Checking exceptions
2022-11-18 01:25:02,002:INFO:Importing libraries
2022-11-18 01:25:02,002:INFO:Copying training dataset
2022-11-18 01:25:02,005:INFO:Defining folds
2022-11-18 01:25:02,005:INFO:Declaring metric variables
2022-11-18 01:25:02,008:INFO:Importing untrained model
2022-11-18 01:25:02,011:INFO:Lasso Regression Imported successfully
2022-11-18 01:25:02,019:INFO:Starting cross validation
2022-11-18 01:25:02,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:02,268:INFO:Calculating mean and std
2022-11-18 01:25:02,268:INFO:Creating metrics dataframe
2022-11-18 01:25:02,271:INFO:Uploading results into container
2022-11-18 01:25:02,272:INFO:Uploading model into container now
2022-11-18 01:25:02,272:INFO:master_model_container: 20
2022-11-18 01:25:02,272:INFO:display_container: 3
2022-11-18 01:25:02,272:INFO:Lasso(random_state=123)
2022-11-18 01:25:02,272:INFO:create_model() successfully completed......................................
2022-11-18 01:25:02,362:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:02,362:INFO:Creating metrics dataframe
2022-11-18 01:25:02,370:INFO:Initializing Ridge Regression
2022-11-18 01:25:02,370:INFO:Total runtime is 0.012582000096638997 minutes
2022-11-18 01:25:02,373:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:02,374:INFO:Initializing create_model()
2022-11-18 01:25:02,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:02,374:INFO:Checking exceptions
2022-11-18 01:25:02,376:INFO:Importing libraries
2022-11-18 01:25:02,376:INFO:Copying training dataset
2022-11-18 01:25:02,379:INFO:Defining folds
2022-11-18 01:25:02,379:INFO:Declaring metric variables
2022-11-18 01:25:02,382:INFO:Importing untrained model
2022-11-18 01:25:02,384:INFO:Ridge Regression Imported successfully
2022-11-18 01:25:02,392:INFO:Starting cross validation
2022-11-18 01:25:02,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:02,658:INFO:Calculating mean and std
2022-11-18 01:25:02,659:INFO:Creating metrics dataframe
2022-11-18 01:25:02,662:INFO:Uploading results into container
2022-11-18 01:25:02,662:INFO:Uploading model into container now
2022-11-18 01:25:02,663:INFO:master_model_container: 21
2022-11-18 01:25:02,663:INFO:display_container: 3
2022-11-18 01:25:02,663:INFO:Ridge(random_state=123)
2022-11-18 01:25:02,663:INFO:create_model() successfully completed......................................
2022-11-18 01:25:02,750:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:02,750:INFO:Creating metrics dataframe
2022-11-18 01:25:02,759:INFO:Initializing Elastic Net
2022-11-18 01:25:02,759:INFO:Total runtime is 0.01906874974568685 minutes
2022-11-18 01:25:02,761:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:02,762:INFO:Initializing create_model()
2022-11-18 01:25:02,762:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:02,762:INFO:Checking exceptions
2022-11-18 01:25:02,764:INFO:Importing libraries
2022-11-18 01:25:02,764:INFO:Copying training dataset
2022-11-18 01:25:02,767:INFO:Defining folds
2022-11-18 01:25:02,767:INFO:Declaring metric variables
2022-11-18 01:25:02,772:INFO:Importing untrained model
2022-11-18 01:25:02,776:INFO:Elastic Net Imported successfully
2022-11-18 01:25:02,784:INFO:Starting cross validation
2022-11-18 01:25:02,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:03,048:INFO:Calculating mean and std
2022-11-18 01:25:03,049:INFO:Creating metrics dataframe
2022-11-18 01:25:03,052:INFO:Uploading results into container
2022-11-18 01:25:03,052:INFO:Uploading model into container now
2022-11-18 01:25:03,052:INFO:master_model_container: 22
2022-11-18 01:25:03,052:INFO:display_container: 3
2022-11-18 01:25:03,053:INFO:ElasticNet(random_state=123)
2022-11-18 01:25:03,053:INFO:create_model() successfully completed......................................
2022-11-18 01:25:03,141:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:03,141:INFO:Creating metrics dataframe
2022-11-18 01:25:03,149:INFO:Initializing Least Angle Regression
2022-11-18 01:25:03,149:INFO:Total runtime is 0.0255729079246521 minutes
2022-11-18 01:25:03,152:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:03,152:INFO:Initializing create_model()
2022-11-18 01:25:03,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:03,152:INFO:Checking exceptions
2022-11-18 01:25:03,155:INFO:Importing libraries
2022-11-18 01:25:03,155:INFO:Copying training dataset
2022-11-18 01:25:03,158:INFO:Defining folds
2022-11-18 01:25:03,158:INFO:Declaring metric variables
2022-11-18 01:25:03,161:INFO:Importing untrained model
2022-11-18 01:25:03,165:INFO:Least Angle Regression Imported successfully
2022-11-18 01:25:03,172:INFO:Starting cross validation
2022-11-18 01:25:03,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:03,275:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,279:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.346e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,279:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,280:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.270e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,280:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.015e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,281:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.850e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,281:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.064e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,282:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.260e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,282:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.418e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,282:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.603e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,283:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.922e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,289:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,290:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,297:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,301:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.951e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,302:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.590e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,303:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.082e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,304:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.095e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,304:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.983e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,305:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.279e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,306:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.491e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,306:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.421e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,307:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,316:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,338:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,343:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.995e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,344:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.425e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,344:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.617e-06, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,344:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.126e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:25:03,392:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,410:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:03,439:INFO:Calculating mean and std
2022-11-18 01:25:03,441:INFO:Creating metrics dataframe
2022-11-18 01:25:03,444:INFO:Uploading results into container
2022-11-18 01:25:03,444:INFO:Uploading model into container now
2022-11-18 01:25:03,445:INFO:master_model_container: 23
2022-11-18 01:25:03,445:INFO:display_container: 3
2022-11-18 01:25:03,445:INFO:Lars(random_state=123)
2022-11-18 01:25:03,445:INFO:create_model() successfully completed......................................
2022-11-18 01:25:03,531:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:03,531:INFO:Creating metrics dataframe
2022-11-18 01:25:03,540:INFO:Initializing Lasso Least Angle Regression
2022-11-18 01:25:03,540:INFO:Total runtime is 0.03208476702372233 minutes
2022-11-18 01:25:03,543:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:03,543:INFO:Initializing create_model()
2022-11-18 01:25:03,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:03,543:INFO:Checking exceptions
2022-11-18 01:25:03,545:INFO:Importing libraries
2022-11-18 01:25:03,545:INFO:Copying training dataset
2022-11-18 01:25:03,549:INFO:Defining folds
2022-11-18 01:25:03,549:INFO:Declaring metric variables
2022-11-18 01:25:03,551:INFO:Importing untrained model
2022-11-18 01:25:03,556:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 01:25:03,563:INFO:Starting cross validation
2022-11-18 01:25:03,565:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:03,673:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,677:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,679:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,698:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,699:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,700:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,711:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,722:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,788:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,791:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:25:03,818:INFO:Calculating mean and std
2022-11-18 01:25:03,820:INFO:Creating metrics dataframe
2022-11-18 01:25:03,823:INFO:Uploading results into container
2022-11-18 01:25:03,823:INFO:Uploading model into container now
2022-11-18 01:25:03,824:INFO:master_model_container: 24
2022-11-18 01:25:03,824:INFO:display_container: 3
2022-11-18 01:25:03,824:INFO:LassoLars(random_state=123)
2022-11-18 01:25:03,824:INFO:create_model() successfully completed......................................
2022-11-18 01:25:03,913:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:03,913:INFO:Creating metrics dataframe
2022-11-18 01:25:03,922:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 01:25:03,922:INFO:Total runtime is 0.038452176253000896 minutes
2022-11-18 01:25:03,925:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:03,925:INFO:Initializing create_model()
2022-11-18 01:25:03,925:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:03,925:INFO:Checking exceptions
2022-11-18 01:25:03,927:INFO:Importing libraries
2022-11-18 01:25:03,928:INFO:Copying training dataset
2022-11-18 01:25:03,931:INFO:Defining folds
2022-11-18 01:25:03,931:INFO:Declaring metric variables
2022-11-18 01:25:03,934:INFO:Importing untrained model
2022-11-18 01:25:03,937:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 01:25:03,943:INFO:Starting cross validation
2022-11-18 01:25:03,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:04,026:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,049:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,068:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,072:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,075:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,081:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,083:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,095:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,153:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,166:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:25:04,196:INFO:Calculating mean and std
2022-11-18 01:25:04,197:INFO:Creating metrics dataframe
2022-11-18 01:25:04,199:INFO:Uploading results into container
2022-11-18 01:25:04,200:INFO:Uploading model into container now
2022-11-18 01:25:04,200:INFO:master_model_container: 25
2022-11-18 01:25:04,200:INFO:display_container: 3
2022-11-18 01:25:04,200:INFO:OrthogonalMatchingPursuit()
2022-11-18 01:25:04,201:INFO:create_model() successfully completed......................................
2022-11-18 01:25:04,288:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:04,289:INFO:Creating metrics dataframe
2022-11-18 01:25:04,296:INFO:Initializing Bayesian Ridge
2022-11-18 01:25:04,296:INFO:Total runtime is 0.04468377431233724 minutes
2022-11-18 01:25:04,298:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:04,299:INFO:Initializing create_model()
2022-11-18 01:25:04,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:04,299:INFO:Checking exceptions
2022-11-18 01:25:04,300:INFO:Importing libraries
2022-11-18 01:25:04,300:INFO:Copying training dataset
2022-11-18 01:25:04,304:INFO:Defining folds
2022-11-18 01:25:04,305:INFO:Declaring metric variables
2022-11-18 01:25:04,308:INFO:Importing untrained model
2022-11-18 01:25:04,311:INFO:Bayesian Ridge Imported successfully
2022-11-18 01:25:04,318:INFO:Starting cross validation
2022-11-18 01:25:04,320:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:04,577:INFO:Calculating mean and std
2022-11-18 01:25:04,579:INFO:Creating metrics dataframe
2022-11-18 01:25:04,581:INFO:Uploading results into container
2022-11-18 01:25:04,582:INFO:Uploading model into container now
2022-11-18 01:25:04,582:INFO:master_model_container: 26
2022-11-18 01:25:04,582:INFO:display_container: 3
2022-11-18 01:25:04,583:INFO:BayesianRidge()
2022-11-18 01:25:04,583:INFO:create_model() successfully completed......................................
2022-11-18 01:25:04,672:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:04,672:INFO:Creating metrics dataframe
2022-11-18 01:25:04,680:INFO:Initializing Passive Aggressive Regressor
2022-11-18 01:25:04,680:INFO:Total runtime is 0.05109330415725708 minutes
2022-11-18 01:25:04,683:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:04,683:INFO:Initializing create_model()
2022-11-18 01:25:04,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:04,683:INFO:Checking exceptions
2022-11-18 01:25:04,685:INFO:Importing libraries
2022-11-18 01:25:04,686:INFO:Copying training dataset
2022-11-18 01:25:04,689:INFO:Defining folds
2022-11-18 01:25:04,690:INFO:Declaring metric variables
2022-11-18 01:25:04,692:INFO:Importing untrained model
2022-11-18 01:25:04,695:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 01:25:04,700:INFO:Starting cross validation
2022-11-18 01:25:04,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:04,951:INFO:Calculating mean and std
2022-11-18 01:25:04,953:INFO:Creating metrics dataframe
2022-11-18 01:25:04,956:INFO:Uploading results into container
2022-11-18 01:25:04,956:INFO:Uploading model into container now
2022-11-18 01:25:04,957:INFO:master_model_container: 27
2022-11-18 01:25:04,957:INFO:display_container: 3
2022-11-18 01:25:04,957:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 01:25:04,957:INFO:create_model() successfully completed......................................
2022-11-18 01:25:05,045:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:05,045:INFO:Creating metrics dataframe
2022-11-18 01:25:05,052:INFO:Initializing Huber Regressor
2022-11-18 01:25:05,052:INFO:Total runtime is 0.05728956460952759 minutes
2022-11-18 01:25:05,055:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:05,056:INFO:Initializing create_model()
2022-11-18 01:25:05,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:05,056:INFO:Checking exceptions
2022-11-18 01:25:05,058:INFO:Importing libraries
2022-11-18 01:25:05,058:INFO:Copying training dataset
2022-11-18 01:25:05,061:INFO:Defining folds
2022-11-18 01:25:05,061:INFO:Declaring metric variables
2022-11-18 01:25:05,064:INFO:Importing untrained model
2022-11-18 01:25:05,067:INFO:Huber Regressor Imported successfully
2022-11-18 01:25:05,073:INFO:Starting cross validation
2022-11-18 01:25:05,075:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:05,342:INFO:Calculating mean and std
2022-11-18 01:25:05,343:INFO:Creating metrics dataframe
2022-11-18 01:25:05,346:INFO:Uploading results into container
2022-11-18 01:25:05,346:INFO:Uploading model into container now
2022-11-18 01:25:05,347:INFO:master_model_container: 28
2022-11-18 01:25:05,347:INFO:display_container: 3
2022-11-18 01:25:05,347:INFO:HuberRegressor()
2022-11-18 01:25:05,347:INFO:create_model() successfully completed......................................
2022-11-18 01:25:05,434:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:05,434:INFO:Creating metrics dataframe
2022-11-18 01:25:05,444:INFO:Initializing K Neighbors Regressor
2022-11-18 01:25:05,444:INFO:Total runtime is 0.06381936868031819 minutes
2022-11-18 01:25:05,447:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:05,447:INFO:Initializing create_model()
2022-11-18 01:25:05,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:05,447:INFO:Checking exceptions
2022-11-18 01:25:05,449:INFO:Importing libraries
2022-11-18 01:25:05,449:INFO:Copying training dataset
2022-11-18 01:25:05,453:INFO:Defining folds
2022-11-18 01:25:05,453:INFO:Declaring metric variables
2022-11-18 01:25:05,457:INFO:Importing untrained model
2022-11-18 01:25:05,460:INFO:K Neighbors Regressor Imported successfully
2022-11-18 01:25:05,466:INFO:Starting cross validation
2022-11-18 01:25:05,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:05,723:INFO:Calculating mean and std
2022-11-18 01:25:05,725:INFO:Creating metrics dataframe
2022-11-18 01:25:05,727:INFO:Uploading results into container
2022-11-18 01:25:05,728:INFO:Uploading model into container now
2022-11-18 01:25:05,728:INFO:master_model_container: 29
2022-11-18 01:25:05,728:INFO:display_container: 3
2022-11-18 01:25:05,728:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 01:25:05,728:INFO:create_model() successfully completed......................................
2022-11-18 01:25:05,817:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:05,817:INFO:Creating metrics dataframe
2022-11-18 01:25:05,827:INFO:Initializing Decision Tree Regressor
2022-11-18 01:25:05,827:INFO:Total runtime is 0.07021197875340779 minutes
2022-11-18 01:25:05,830:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:05,831:INFO:Initializing create_model()
2022-11-18 01:25:05,831:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:05,831:INFO:Checking exceptions
2022-11-18 01:25:05,832:INFO:Importing libraries
2022-11-18 01:25:05,833:INFO:Copying training dataset
2022-11-18 01:25:05,836:INFO:Defining folds
2022-11-18 01:25:05,836:INFO:Declaring metric variables
2022-11-18 01:25:05,839:INFO:Importing untrained model
2022-11-18 01:25:05,842:INFO:Decision Tree Regressor Imported successfully
2022-11-18 01:25:05,848:INFO:Starting cross validation
2022-11-18 01:25:05,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:06,105:INFO:Calculating mean and std
2022-11-18 01:25:06,107:INFO:Creating metrics dataframe
2022-11-18 01:25:06,110:INFO:Uploading results into container
2022-11-18 01:25:06,110:INFO:Uploading model into container now
2022-11-18 01:25:06,111:INFO:master_model_container: 30
2022-11-18 01:25:06,111:INFO:display_container: 3
2022-11-18 01:25:06,111:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 01:25:06,111:INFO:create_model() successfully completed......................................
2022-11-18 01:25:06,203:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:06,203:INFO:Creating metrics dataframe
2022-11-18 01:25:06,213:INFO:Initializing Random Forest Regressor
2022-11-18 01:25:06,213:INFO:Total runtime is 0.07663753430048624 minutes
2022-11-18 01:25:06,216:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:06,216:INFO:Initializing create_model()
2022-11-18 01:25:06,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:06,216:INFO:Checking exceptions
2022-11-18 01:25:06,218:INFO:Importing libraries
2022-11-18 01:25:06,218:INFO:Copying training dataset
2022-11-18 01:25:06,223:INFO:Defining folds
2022-11-18 01:25:06,223:INFO:Declaring metric variables
2022-11-18 01:25:06,226:INFO:Importing untrained model
2022-11-18 01:25:06,229:INFO:Random Forest Regressor Imported successfully
2022-11-18 01:25:06,235:INFO:Starting cross validation
2022-11-18 01:25:06,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:25:07,089:INFO:Calculating mean and std
2022-11-18 01:25:07,091:INFO:Creating metrics dataframe
2022-11-18 01:25:07,093:INFO:Uploading results into container
2022-11-18 01:25:07,093:INFO:Uploading model into container now
2022-11-18 01:25:07,094:INFO:master_model_container: 31
2022-11-18 01:25:07,094:INFO:display_container: 3
2022-11-18 01:25:07,094:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:25:07,094:INFO:create_model() successfully completed......................................
2022-11-18 01:25:07,181:INFO:SubProcess create_model() end ==================================
2022-11-18 01:25:07,181:INFO:Creating metrics dataframe
2022-11-18 01:25:07,191:INFO:Initializing Extra Trees Regressor
2022-11-18 01:25:07,191:INFO:Total runtime is 0.09293662707010905 minutes
2022-11-18 01:25:07,194:INFO:SubProcess create_model() called ==================================
2022-11-18 01:25:07,194:INFO:Initializing create_model()
2022-11-18 01:25:07,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46dfd1c0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:25:07,194:INFO:Checking exceptions
2022-11-18 01:25:07,197:INFO:Importing libraries
2022-11-18 01:25:07,197:INFO:Copying training dataset
2022-11-18 01:25:07,200:INFO:Defining folds
2022-11-18 01:25:07,200:INFO:Declaring metric variables
2022-11-18 01:25:07,203:INFO:Importing untrained model
2022-11-18 01:25:07,207:INFO:Extra Trees Regressor Imported successfully
2022-11-18 01:25:07,212:INFO:Starting cross validation
2022-11-18 01:25:07,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:52,660:INFO:Initializing compare_models()
2022-11-18 01:26:52,660:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, 'include': None, 'exclude': ['ransac'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['ransac'])
2022-11-18 01:26:52,660:INFO:Checking exceptions
2022-11-18 01:26:52,663:INFO:Preparing display monitor
2022-11-18 01:26:52,697:INFO:Initializing Linear Regression
2022-11-18 01:26:52,697:INFO:Total runtime is 3.361701965332031e-06 minutes
2022-11-18 01:26:52,700:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:52,700:INFO:Initializing create_model()
2022-11-18 01:26:52,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:52,701:INFO:Checking exceptions
2022-11-18 01:26:52,703:INFO:Importing libraries
2022-11-18 01:26:52,703:INFO:Copying training dataset
2022-11-18 01:26:52,707:INFO:Defining folds
2022-11-18 01:26:52,707:INFO:Declaring metric variables
2022-11-18 01:26:52,712:INFO:Importing untrained model
2022-11-18 01:26:52,716:INFO:Linear Regression Imported successfully
2022-11-18 01:26:52,725:INFO:Starting cross validation
2022-11-18 01:26:52,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:54,537:INFO:Calculating mean and std
2022-11-18 01:26:54,539:INFO:Creating metrics dataframe
2022-11-18 01:26:54,543:INFO:Uploading results into container
2022-11-18 01:26:54,543:INFO:Uploading model into container now
2022-11-18 01:26:54,544:INFO:master_model_container: 32
2022-11-18 01:26:54,544:INFO:display_container: 3
2022-11-18 01:26:54,544:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:26:54,544:INFO:create_model() successfully completed......................................
2022-11-18 01:26:54,661:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:54,661:INFO:Creating metrics dataframe
2022-11-18 01:26:54,667:INFO:Initializing Lasso Regression
2022-11-18 01:26:54,667:INFO:Total runtime is 0.03283856312433879 minutes
2022-11-18 01:26:54,670:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:54,671:INFO:Initializing create_model()
2022-11-18 01:26:54,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:54,671:INFO:Checking exceptions
2022-11-18 01:26:54,673:INFO:Importing libraries
2022-11-18 01:26:54,673:INFO:Copying training dataset
2022-11-18 01:26:54,676:INFO:Defining folds
2022-11-18 01:26:54,676:INFO:Declaring metric variables
2022-11-18 01:26:54,679:INFO:Importing untrained model
2022-11-18 01:26:54,682:INFO:Lasso Regression Imported successfully
2022-11-18 01:26:54,690:INFO:Starting cross validation
2022-11-18 01:26:54,693:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:54,945:INFO:Calculating mean and std
2022-11-18 01:26:54,946:INFO:Creating metrics dataframe
2022-11-18 01:26:54,949:INFO:Uploading results into container
2022-11-18 01:26:54,949:INFO:Uploading model into container now
2022-11-18 01:26:54,950:INFO:master_model_container: 33
2022-11-18 01:26:54,950:INFO:display_container: 3
2022-11-18 01:26:54,950:INFO:Lasso(random_state=123)
2022-11-18 01:26:54,950:INFO:create_model() successfully completed......................................
2022-11-18 01:26:55,055:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:55,055:INFO:Creating metrics dataframe
2022-11-18 01:26:55,063:INFO:Initializing Ridge Regression
2022-11-18 01:26:55,063:INFO:Total runtime is 0.039441275596618655 minutes
2022-11-18 01:26:55,066:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:55,066:INFO:Initializing create_model()
2022-11-18 01:26:55,066:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:55,066:INFO:Checking exceptions
2022-11-18 01:26:55,068:INFO:Importing libraries
2022-11-18 01:26:55,068:INFO:Copying training dataset
2022-11-18 01:26:55,072:INFO:Defining folds
2022-11-18 01:26:55,072:INFO:Declaring metric variables
2022-11-18 01:26:55,075:INFO:Importing untrained model
2022-11-18 01:26:55,078:INFO:Ridge Regression Imported successfully
2022-11-18 01:26:55,084:INFO:Starting cross validation
2022-11-18 01:26:55,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:55,338:INFO:Calculating mean and std
2022-11-18 01:26:55,339:INFO:Creating metrics dataframe
2022-11-18 01:26:55,342:INFO:Uploading results into container
2022-11-18 01:26:55,342:INFO:Uploading model into container now
2022-11-18 01:26:55,342:INFO:master_model_container: 34
2022-11-18 01:26:55,343:INFO:display_container: 3
2022-11-18 01:26:55,343:INFO:Ridge(random_state=123)
2022-11-18 01:26:55,343:INFO:create_model() successfully completed......................................
2022-11-18 01:26:55,445:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:55,446:INFO:Creating metrics dataframe
2022-11-18 01:26:55,456:INFO:Initializing Elastic Net
2022-11-18 01:26:55,456:INFO:Total runtime is 0.04598396221796672 minutes
2022-11-18 01:26:55,458:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:55,459:INFO:Initializing create_model()
2022-11-18 01:26:55,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:55,459:INFO:Checking exceptions
2022-11-18 01:26:55,461:INFO:Importing libraries
2022-11-18 01:26:55,461:INFO:Copying training dataset
2022-11-18 01:26:55,464:INFO:Defining folds
2022-11-18 01:26:55,464:INFO:Declaring metric variables
2022-11-18 01:26:55,467:INFO:Importing untrained model
2022-11-18 01:26:55,471:INFO:Elastic Net Imported successfully
2022-11-18 01:26:55,477:INFO:Starting cross validation
2022-11-18 01:26:55,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:55,726:INFO:Calculating mean and std
2022-11-18 01:26:55,728:INFO:Creating metrics dataframe
2022-11-18 01:26:55,730:INFO:Uploading results into container
2022-11-18 01:26:55,731:INFO:Uploading model into container now
2022-11-18 01:26:55,731:INFO:master_model_container: 35
2022-11-18 01:26:55,731:INFO:display_container: 3
2022-11-18 01:26:55,731:INFO:ElasticNet(random_state=123)
2022-11-18 01:26:55,731:INFO:create_model() successfully completed......................................
2022-11-18 01:26:55,834:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:55,834:INFO:Creating metrics dataframe
2022-11-18 01:26:55,842:INFO:Initializing Least Angle Regression
2022-11-18 01:26:55,842:INFO:Total runtime is 0.05242735544840495 minutes
2022-11-18 01:26:55,845:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:55,845:INFO:Initializing create_model()
2022-11-18 01:26:55,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:55,845:INFO:Checking exceptions
2022-11-18 01:26:55,847:INFO:Importing libraries
2022-11-18 01:26:55,847:INFO:Copying training dataset
2022-11-18 01:26:55,850:INFO:Defining folds
2022-11-18 01:26:55,851:INFO:Declaring metric variables
2022-11-18 01:26:55,854:INFO:Importing untrained model
2022-11-18 01:26:55,857:INFO:Least Angle Regression Imported successfully
2022-11-18 01:26:55,863:INFO:Starting cross validation
2022-11-18 01:26:55,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:55,950:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:55,966:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:55,979:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:55,983:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.346e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,983:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:55,984:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.270e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,985:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.015e-05, with an active set of 16 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,986:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.850e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,986:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.064e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,987:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.260e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,987:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.418e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,988:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.603e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 4.081e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,988:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.922e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:55,996:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,000:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.951e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,002:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.590e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,003:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.082e-04, with an active set of 17 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,004:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=4.095e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,004:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.983e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,005:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.279e-05, with an active set of 19 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,005:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.491e-05, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,006:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.421e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.144e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,012:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,022:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,026:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,031:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.995e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,031:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.425e-05, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.424e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,032:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.617e-06, with an active set of 18 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,032:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=3.126e-06, with an active set of 19 regressors, and the smallest cholesky pivot element being 5.268e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2022-11-18 01:26:56,089:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,090:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,120:INFO:Calculating mean and std
2022-11-18 01:26:56,122:INFO:Creating metrics dataframe
2022-11-18 01:26:56,124:INFO:Uploading results into container
2022-11-18 01:26:56,125:INFO:Uploading model into container now
2022-11-18 01:26:56,125:INFO:master_model_container: 36
2022-11-18 01:26:56,125:INFO:display_container: 3
2022-11-18 01:26:56,126:INFO:Lars(random_state=123)
2022-11-18 01:26:56,126:INFO:create_model() successfully completed......................................
2022-11-18 01:26:56,228:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:56,228:INFO:Creating metrics dataframe
2022-11-18 01:26:56,235:INFO:Initializing Lasso Least Angle Regression
2022-11-18 01:26:56,235:INFO:Total runtime is 0.058978398640950516 minutes
2022-11-18 01:26:56,238:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:56,239:INFO:Initializing create_model()
2022-11-18 01:26:56,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:56,239:INFO:Checking exceptions
2022-11-18 01:26:56,241:INFO:Importing libraries
2022-11-18 01:26:56,241:INFO:Copying training dataset
2022-11-18 01:26:56,244:INFO:Defining folds
2022-11-18 01:26:56,244:INFO:Declaring metric variables
2022-11-18 01:26:56,247:INFO:Importing untrained model
2022-11-18 01:26:56,250:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 01:26:56,257:INFO:Starting cross validation
2022-11-18 01:26:56,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:56,344:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,366:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,369:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,383:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,383:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,384:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,405:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,426:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,489:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,493:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-11-18 01:26:56,530:INFO:Calculating mean and std
2022-11-18 01:26:56,532:INFO:Creating metrics dataframe
2022-11-18 01:26:56,535:INFO:Uploading results into container
2022-11-18 01:26:56,536:INFO:Uploading model into container now
2022-11-18 01:26:56,537:INFO:master_model_container: 37
2022-11-18 01:26:56,537:INFO:display_container: 3
2022-11-18 01:26:56,537:INFO:LassoLars(random_state=123)
2022-11-18 01:26:56,537:INFO:create_model() successfully completed......................................
2022-11-18 01:26:56,638:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:56,638:INFO:Creating metrics dataframe
2022-11-18 01:26:56,647:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 01:26:56,647:INFO:Total runtime is 0.06583329041798909 minutes
2022-11-18 01:26:56,649:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:56,650:INFO:Initializing create_model()
2022-11-18 01:26:56,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:56,650:INFO:Checking exceptions
2022-11-18 01:26:56,652:INFO:Importing libraries
2022-11-18 01:26:56,652:INFO:Copying training dataset
2022-11-18 01:26:56,656:INFO:Defining folds
2022-11-18 01:26:56,656:INFO:Declaring metric variables
2022-11-18 01:26:56,659:INFO:Importing untrained model
2022-11-18 01:26:56,662:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 01:26:56,668:INFO:Starting cross validation
2022-11-18 01:26:56,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:56,774:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,777:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,778:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,792:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,796:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,807:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,810:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,829:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,889:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,891:WARNING:/home/gfragi/PycharmProjects/py_regression/reg_pycaret/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-11-18 01:26:56,921:INFO:Calculating mean and std
2022-11-18 01:26:56,922:INFO:Creating metrics dataframe
2022-11-18 01:26:56,925:INFO:Uploading results into container
2022-11-18 01:26:56,925:INFO:Uploading model into container now
2022-11-18 01:26:56,926:INFO:master_model_container: 38
2022-11-18 01:26:56,926:INFO:display_container: 3
2022-11-18 01:26:56,926:INFO:OrthogonalMatchingPursuit()
2022-11-18 01:26:56,926:INFO:create_model() successfully completed......................................
2022-11-18 01:26:57,027:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:57,027:INFO:Creating metrics dataframe
2022-11-18 01:26:57,034:INFO:Initializing Bayesian Ridge
2022-11-18 01:26:57,035:INFO:Total runtime is 0.0722987174987793 minutes
2022-11-18 01:26:57,038:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:57,039:INFO:Initializing create_model()
2022-11-18 01:26:57,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:57,039:INFO:Checking exceptions
2022-11-18 01:26:57,040:INFO:Importing libraries
2022-11-18 01:26:57,041:INFO:Copying training dataset
2022-11-18 01:26:57,044:INFO:Defining folds
2022-11-18 01:26:57,044:INFO:Declaring metric variables
2022-11-18 01:26:57,047:INFO:Importing untrained model
2022-11-18 01:26:57,050:INFO:Bayesian Ridge Imported successfully
2022-11-18 01:26:57,057:INFO:Starting cross validation
2022-11-18 01:26:57,059:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:57,310:INFO:Calculating mean and std
2022-11-18 01:26:57,311:INFO:Creating metrics dataframe
2022-11-18 01:26:57,314:INFO:Uploading results into container
2022-11-18 01:26:57,314:INFO:Uploading model into container now
2022-11-18 01:26:57,315:INFO:master_model_container: 39
2022-11-18 01:26:57,315:INFO:display_container: 3
2022-11-18 01:26:57,315:INFO:BayesianRidge()
2022-11-18 01:26:57,315:INFO:create_model() successfully completed......................................
2022-11-18 01:26:57,415:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:57,415:INFO:Creating metrics dataframe
2022-11-18 01:26:57,426:INFO:Initializing Passive Aggressive Regressor
2022-11-18 01:26:57,426:INFO:Total runtime is 0.07882626056671142 minutes
2022-11-18 01:26:57,429:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:57,430:INFO:Initializing create_model()
2022-11-18 01:26:57,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:57,430:INFO:Checking exceptions
2022-11-18 01:26:57,432:INFO:Importing libraries
2022-11-18 01:26:57,432:INFO:Copying training dataset
2022-11-18 01:26:57,437:INFO:Defining folds
2022-11-18 01:26:57,437:INFO:Declaring metric variables
2022-11-18 01:26:57,440:INFO:Importing untrained model
2022-11-18 01:26:57,444:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 01:26:57,450:INFO:Starting cross validation
2022-11-18 01:26:57,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:57,704:INFO:Calculating mean and std
2022-11-18 01:26:57,706:INFO:Creating metrics dataframe
2022-11-18 01:26:57,709:INFO:Uploading results into container
2022-11-18 01:26:57,709:INFO:Uploading model into container now
2022-11-18 01:26:57,710:INFO:master_model_container: 40
2022-11-18 01:26:57,710:INFO:display_container: 3
2022-11-18 01:26:57,710:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 01:26:57,710:INFO:create_model() successfully completed......................................
2022-11-18 01:26:57,813:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:57,813:INFO:Creating metrics dataframe
2022-11-18 01:26:57,823:INFO:Initializing Huber Regressor
2022-11-18 01:26:57,823:INFO:Total runtime is 0.0854376196861267 minutes
2022-11-18 01:26:57,826:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:57,826:INFO:Initializing create_model()
2022-11-18 01:26:57,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:57,826:INFO:Checking exceptions
2022-11-18 01:26:57,828:INFO:Importing libraries
2022-11-18 01:26:57,828:INFO:Copying training dataset
2022-11-18 01:26:57,831:INFO:Defining folds
2022-11-18 01:26:57,831:INFO:Declaring metric variables
2022-11-18 01:26:57,834:INFO:Importing untrained model
2022-11-18 01:26:57,837:INFO:Huber Regressor Imported successfully
2022-11-18 01:26:57,843:INFO:Starting cross validation
2022-11-18 01:26:57,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:58,115:INFO:Calculating mean and std
2022-11-18 01:26:58,116:INFO:Creating metrics dataframe
2022-11-18 01:26:58,120:INFO:Uploading results into container
2022-11-18 01:26:58,121:INFO:Uploading model into container now
2022-11-18 01:26:58,122:INFO:master_model_container: 41
2022-11-18 01:26:58,122:INFO:display_container: 3
2022-11-18 01:26:58,122:INFO:HuberRegressor()
2022-11-18 01:26:58,122:INFO:create_model() successfully completed......................................
2022-11-18 01:26:58,224:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:58,225:INFO:Creating metrics dataframe
2022-11-18 01:26:58,234:INFO:Initializing K Neighbors Regressor
2022-11-18 01:26:58,234:INFO:Total runtime is 0.09228917757670084 minutes
2022-11-18 01:26:58,238:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:58,238:INFO:Initializing create_model()
2022-11-18 01:26:58,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:58,238:INFO:Checking exceptions
2022-11-18 01:26:58,239:INFO:Importing libraries
2022-11-18 01:26:58,240:INFO:Copying training dataset
2022-11-18 01:26:58,243:INFO:Defining folds
2022-11-18 01:26:58,243:INFO:Declaring metric variables
2022-11-18 01:26:58,246:INFO:Importing untrained model
2022-11-18 01:26:58,249:INFO:K Neighbors Regressor Imported successfully
2022-11-18 01:26:58,258:INFO:Starting cross validation
2022-11-18 01:26:58,260:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:58,546:INFO:Calculating mean and std
2022-11-18 01:26:58,548:INFO:Creating metrics dataframe
2022-11-18 01:26:58,550:INFO:Uploading results into container
2022-11-18 01:26:58,551:INFO:Uploading model into container now
2022-11-18 01:26:58,551:INFO:master_model_container: 42
2022-11-18 01:26:58,551:INFO:display_container: 3
2022-11-18 01:26:58,551:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 01:26:58,552:INFO:create_model() successfully completed......................................
2022-11-18 01:26:58,655:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:58,655:INFO:Creating metrics dataframe
2022-11-18 01:26:58,663:INFO:Initializing Decision Tree Regressor
2022-11-18 01:26:58,663:INFO:Total runtime is 0.09944667816162109 minutes
2022-11-18 01:26:58,666:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:58,667:INFO:Initializing create_model()
2022-11-18 01:26:58,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:58,667:INFO:Checking exceptions
2022-11-18 01:26:58,669:INFO:Importing libraries
2022-11-18 01:26:58,669:INFO:Copying training dataset
2022-11-18 01:26:58,673:INFO:Defining folds
2022-11-18 01:26:58,673:INFO:Declaring metric variables
2022-11-18 01:26:58,676:INFO:Importing untrained model
2022-11-18 01:26:58,679:INFO:Decision Tree Regressor Imported successfully
2022-11-18 01:26:58,689:INFO:Starting cross validation
2022-11-18 01:26:58,691:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:58,962:INFO:Calculating mean and std
2022-11-18 01:26:58,963:INFO:Creating metrics dataframe
2022-11-18 01:26:58,965:INFO:Uploading results into container
2022-11-18 01:26:58,966:INFO:Uploading model into container now
2022-11-18 01:26:58,966:INFO:master_model_container: 43
2022-11-18 01:26:58,966:INFO:display_container: 3
2022-11-18 01:26:58,967:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 01:26:58,967:INFO:create_model() successfully completed......................................
2022-11-18 01:26:59,068:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:59,068:INFO:Creating metrics dataframe
2022-11-18 01:26:59,078:INFO:Initializing Random Forest Regressor
2022-11-18 01:26:59,078:INFO:Total runtime is 0.10635118087132771 minutes
2022-11-18 01:26:59,080:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:59,080:INFO:Initializing create_model()
2022-11-18 01:26:59,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:59,080:INFO:Checking exceptions
2022-11-18 01:26:59,082:INFO:Importing libraries
2022-11-18 01:26:59,083:INFO:Copying training dataset
2022-11-18 01:26:59,087:INFO:Defining folds
2022-11-18 01:26:59,087:INFO:Declaring metric variables
2022-11-18 01:26:59,090:INFO:Importing untrained model
2022-11-18 01:26:59,093:INFO:Random Forest Regressor Imported successfully
2022-11-18 01:26:59,098:INFO:Starting cross validation
2022-11-18 01:26:59,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:26:59,864:INFO:Calculating mean and std
2022-11-18 01:26:59,865:INFO:Creating metrics dataframe
2022-11-18 01:26:59,869:INFO:Uploading results into container
2022-11-18 01:26:59,869:INFO:Uploading model into container now
2022-11-18 01:26:59,870:INFO:master_model_container: 44
2022-11-18 01:26:59,870:INFO:display_container: 3
2022-11-18 01:26:59,870:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:26:59,870:INFO:create_model() successfully completed......................................
2022-11-18 01:26:59,975:INFO:SubProcess create_model() end ==================================
2022-11-18 01:26:59,975:INFO:Creating metrics dataframe
2022-11-18 01:26:59,984:INFO:Initializing Extra Trees Regressor
2022-11-18 01:26:59,984:INFO:Total runtime is 0.1214533766110738 minutes
2022-11-18 01:26:59,987:INFO:SubProcess create_model() called ==================================
2022-11-18 01:26:59,987:INFO:Initializing create_model()
2022-11-18 01:26:59,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:26:59,987:INFO:Checking exceptions
2022-11-18 01:26:59,990:INFO:Importing libraries
2022-11-18 01:26:59,990:INFO:Copying training dataset
2022-11-18 01:26:59,993:INFO:Defining folds
2022-11-18 01:26:59,993:INFO:Declaring metric variables
2022-11-18 01:26:59,996:INFO:Importing untrained model
2022-11-18 01:27:00,000:INFO:Extra Trees Regressor Imported successfully
2022-11-18 01:27:00,006:INFO:Starting cross validation
2022-11-18 01:27:00,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:27:00,642:INFO:Calculating mean and std
2022-11-18 01:27:00,643:INFO:Creating metrics dataframe
2022-11-18 01:27:00,646:INFO:Uploading results into container
2022-11-18 01:27:00,646:INFO:Uploading model into container now
2022-11-18 01:27:00,647:INFO:master_model_container: 45
2022-11-18 01:27:00,647:INFO:display_container: 3
2022-11-18 01:27:00,647:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:27:00,647:INFO:create_model() successfully completed......................................
2022-11-18 01:27:00,749:INFO:SubProcess create_model() end ==================================
2022-11-18 01:27:00,749:INFO:Creating metrics dataframe
2022-11-18 01:27:00,759:INFO:Initializing AdaBoost Regressor
2022-11-18 01:27:00,760:INFO:Total runtime is 0.1343813459078471 minutes
2022-11-18 01:27:00,762:INFO:SubProcess create_model() called ==================================
2022-11-18 01:27:00,762:INFO:Initializing create_model()
2022-11-18 01:27:00,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:00,763:INFO:Checking exceptions
2022-11-18 01:27:00,765:INFO:Importing libraries
2022-11-18 01:27:00,765:INFO:Copying training dataset
2022-11-18 01:27:00,769:INFO:Defining folds
2022-11-18 01:27:00,769:INFO:Declaring metric variables
2022-11-18 01:27:00,772:INFO:Importing untrained model
2022-11-18 01:27:00,775:INFO:AdaBoost Regressor Imported successfully
2022-11-18 01:27:00,781:INFO:Starting cross validation
2022-11-18 01:27:00,782:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:27:01,226:INFO:Calculating mean and std
2022-11-18 01:27:01,227:INFO:Creating metrics dataframe
2022-11-18 01:27:01,230:INFO:Uploading results into container
2022-11-18 01:27:01,230:INFO:Uploading model into container now
2022-11-18 01:27:01,231:INFO:master_model_container: 46
2022-11-18 01:27:01,231:INFO:display_container: 3
2022-11-18 01:27:01,231:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 01:27:01,231:INFO:create_model() successfully completed......................................
2022-11-18 01:27:01,331:INFO:SubProcess create_model() end ==================================
2022-11-18 01:27:01,331:INFO:Creating metrics dataframe
2022-11-18 01:27:01,342:INFO:Initializing Gradient Boosting Regressor
2022-11-18 01:27:01,342:INFO:Total runtime is 0.14408636887868245 minutes
2022-11-18 01:27:01,344:INFO:SubProcess create_model() called ==================================
2022-11-18 01:27:01,345:INFO:Initializing create_model()
2022-11-18 01:27:01,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:01,345:INFO:Checking exceptions
2022-11-18 01:27:01,346:INFO:Importing libraries
2022-11-18 01:27:01,346:INFO:Copying training dataset
2022-11-18 01:27:01,349:INFO:Defining folds
2022-11-18 01:27:01,350:INFO:Declaring metric variables
2022-11-18 01:27:01,353:INFO:Importing untrained model
2022-11-18 01:27:01,356:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 01:27:01,361:INFO:Starting cross validation
2022-11-18 01:27:01,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:27:01,829:INFO:Calculating mean and std
2022-11-18 01:27:01,831:INFO:Creating metrics dataframe
2022-11-18 01:27:01,833:INFO:Uploading results into container
2022-11-18 01:27:01,834:INFO:Uploading model into container now
2022-11-18 01:27:01,834:INFO:master_model_container: 47
2022-11-18 01:27:01,835:INFO:display_container: 3
2022-11-18 01:27:01,835:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 01:27:01,835:INFO:create_model() successfully completed......................................
2022-11-18 01:27:01,937:INFO:SubProcess create_model() end ==================================
2022-11-18 01:27:01,937:INFO:Creating metrics dataframe
2022-11-18 01:27:01,946:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 01:27:01,946:INFO:Total runtime is 0.15415563583374023 minutes
2022-11-18 01:27:01,949:INFO:SubProcess create_model() called ==================================
2022-11-18 01:27:01,949:INFO:Initializing create_model()
2022-11-18 01:27:01,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:01,949:INFO:Checking exceptions
2022-11-18 01:27:01,952:INFO:Importing libraries
2022-11-18 01:27:01,952:INFO:Copying training dataset
2022-11-18 01:27:01,956:INFO:Defining folds
2022-11-18 01:27:01,956:INFO:Declaring metric variables
2022-11-18 01:27:01,959:INFO:Importing untrained model
2022-11-18 01:27:01,963:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 01:27:01,971:INFO:Starting cross validation
2022-11-18 01:27:01,973:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:27:02,299:INFO:Calculating mean and std
2022-11-18 01:27:02,300:INFO:Creating metrics dataframe
2022-11-18 01:27:02,304:INFO:Uploading results into container
2022-11-18 01:27:02,304:INFO:Uploading model into container now
2022-11-18 01:27:02,305:INFO:master_model_container: 48
2022-11-18 01:27:02,305:INFO:display_container: 3
2022-11-18 01:27:02,305:INFO:LGBMRegressor(random_state=123)
2022-11-18 01:27:02,305:INFO:create_model() successfully completed......................................
2022-11-18 01:27:02,406:INFO:SubProcess create_model() end ==================================
2022-11-18 01:27:02,406:INFO:Creating metrics dataframe
2022-11-18 01:27:02,414:INFO:Initializing Dummy Regressor
2022-11-18 01:27:02,414:INFO:Total runtime is 0.1619596838951111 minutes
2022-11-18 01:27:02,417:INFO:SubProcess create_model() called ==================================
2022-11-18 01:27:02,417:INFO:Initializing create_model()
2022-11-18 01:27:02,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d46d8d5e0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:02,417:INFO:Checking exceptions
2022-11-18 01:27:02,420:INFO:Importing libraries
2022-11-18 01:27:02,420:INFO:Copying training dataset
2022-11-18 01:27:02,423:INFO:Defining folds
2022-11-18 01:27:02,423:INFO:Declaring metric variables
2022-11-18 01:27:02,426:INFO:Importing untrained model
2022-11-18 01:27:02,429:INFO:Dummy Regressor Imported successfully
2022-11-18 01:27:02,435:INFO:Starting cross validation
2022-11-18 01:27:02,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:27:02,694:INFO:Calculating mean and std
2022-11-18 01:27:02,695:INFO:Creating metrics dataframe
2022-11-18 01:27:02,698:INFO:Uploading results into container
2022-11-18 01:27:02,698:INFO:Uploading model into container now
2022-11-18 01:27:02,699:INFO:master_model_container: 49
2022-11-18 01:27:02,699:INFO:display_container: 3
2022-11-18 01:27:02,699:INFO:DummyRegressor()
2022-11-18 01:27:02,699:INFO:create_model() successfully completed......................................
2022-11-18 01:27:02,801:INFO:SubProcess create_model() end ==================================
2022-11-18 01:27:02,802:INFO:Creating metrics dataframe
2022-11-18 01:27:02,819:INFO:Initializing create_model()
2022-11-18 01:27:02,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:02,820:INFO:Checking exceptions
2022-11-18 01:27:02,823:INFO:Importing libraries
2022-11-18 01:27:02,823:INFO:Copying training dataset
2022-11-18 01:27:02,826:INFO:Defining folds
2022-11-18 01:27:02,826:INFO:Declaring metric variables
2022-11-18 01:27:02,826:INFO:Importing untrained model
2022-11-18 01:27:02,826:INFO:Declaring custom model
2022-11-18 01:27:02,827:INFO:Extra Trees Regressor Imported successfully
2022-11-18 01:27:02,829:INFO:Cross validation set to False
2022-11-18 01:27:02,829:INFO:Fitting Model
2022-11-18 01:27:02,962:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:27:02,962:INFO:create_model() successfully completed......................................
2022-11-18 01:27:03,073:INFO:Initializing create_model()
2022-11-18 01:27:03,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:03,074:INFO:Checking exceptions
2022-11-18 01:27:03,077:INFO:Importing libraries
2022-11-18 01:27:03,077:INFO:Copying training dataset
2022-11-18 01:27:03,079:INFO:Defining folds
2022-11-18 01:27:03,079:INFO:Declaring metric variables
2022-11-18 01:27:03,079:INFO:Importing untrained model
2022-11-18 01:27:03,079:INFO:Declaring custom model
2022-11-18 01:27:03,080:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 01:27:03,081:INFO:Cross validation set to False
2022-11-18 01:27:03,081:INFO:Fitting Model
2022-11-18 01:27:03,164:INFO:LGBMRegressor(random_state=123)
2022-11-18 01:27:03,164:INFO:create_model() successfully completed......................................
2022-11-18 01:27:03,271:INFO:Initializing create_model()
2022-11-18 01:27:03,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:03,271:INFO:Checking exceptions
2022-11-18 01:27:03,275:INFO:Importing libraries
2022-11-18 01:27:03,275:INFO:Copying training dataset
2022-11-18 01:27:03,277:INFO:Defining folds
2022-11-18 01:27:03,277:INFO:Declaring metric variables
2022-11-18 01:27:03,277:INFO:Importing untrained model
2022-11-18 01:27:03,277:INFO:Declaring custom model
2022-11-18 01:27:03,278:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 01:27:03,279:INFO:Cross validation set to False
2022-11-18 01:27:03,279:INFO:Fitting Model
2022-11-18 01:27:03,386:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 01:27:03,386:INFO:create_model() successfully completed......................................
2022-11-18 01:27:03,492:INFO:Initializing create_model()
2022-11-18 01:27:03,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:03,492:INFO:Checking exceptions
2022-11-18 01:27:03,495:INFO:Importing libraries
2022-11-18 01:27:03,495:INFO:Copying training dataset
2022-11-18 01:27:03,498:INFO:Defining folds
2022-11-18 01:27:03,498:INFO:Declaring metric variables
2022-11-18 01:27:03,498:INFO:Importing untrained model
2022-11-18 01:27:03,498:INFO:Declaring custom model
2022-11-18 01:27:03,499:INFO:Random Forest Regressor Imported successfully
2022-11-18 01:27:03,500:INFO:Cross validation set to False
2022-11-18 01:27:03,500:INFO:Fitting Model
2022-11-18 01:27:03,652:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 01:27:03,652:INFO:create_model() successfully completed......................................
2022-11-18 01:27:03,757:INFO:Initializing create_model()
2022-11-18 01:27:03,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:27:03,757:INFO:Checking exceptions
2022-11-18 01:27:03,760:INFO:Importing libraries
2022-11-18 01:27:03,760:INFO:Copying training dataset
2022-11-18 01:27:03,763:INFO:Defining folds
2022-11-18 01:27:03,763:INFO:Declaring metric variables
2022-11-18 01:27:03,763:INFO:Importing untrained model
2022-11-18 01:27:03,763:INFO:Declaring custom model
2022-11-18 01:27:03,763:INFO:AdaBoost Regressor Imported successfully
2022-11-18 01:27:03,764:INFO:Cross validation set to False
2022-11-18 01:27:03,765:INFO:Fitting Model
2022-11-18 01:27:03,872:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 01:27:03,872:INFO:create_model() successfully completed......................................
2022-11-18 01:27:03,991:INFO:master_model_container: 49
2022-11-18 01:27:03,991:INFO:display_container: 3
2022-11-18 01:27:03,992:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), LGBMRegressor(random_state=123), GradientBoostingRegressor(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), AdaBoostRegressor(random_state=123)]
2022-11-18 01:27:03,992:INFO:compare_models() successfully completed......................................
2022-11-18 01:31:52,734:INFO:Initializing create_model()
2022-11-18 01:31:52,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:31:52,735:INFO:Checking exceptions
2022-11-18 01:31:52,759:INFO:Importing libraries
2022-11-18 01:31:52,759:INFO:Copying training dataset
2022-11-18 01:31:52,762:INFO:Defining folds
2022-11-18 01:31:52,762:INFO:Declaring metric variables
2022-11-18 01:31:52,765:INFO:Importing untrained model
2022-11-18 01:31:52,770:INFO:Decision Tree Regressor Imported successfully
2022-11-18 01:31:52,778:INFO:Starting cross validation
2022-11-18 01:31:52,780:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:31:53,910:INFO:Calculating mean and std
2022-11-18 01:31:53,911:INFO:Creating metrics dataframe
2022-11-18 01:31:53,915:INFO:Finalizing model
2022-11-18 01:31:53,975:INFO:Uploading results into container
2022-11-18 01:31:53,976:INFO:Uploading model into container now
2022-11-18 01:31:53,982:INFO:master_model_container: 50
2022-11-18 01:31:53,983:INFO:display_container: 4
2022-11-18 01:31:53,983:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 01:31:53,983:INFO:create_model() successfully completed......................................
2022-11-18 01:32:35,677:INFO:Initializing create_model()
2022-11-18 01:32:35,677:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:32:35,678:INFO:Checking exceptions
2022-11-18 01:32:35,711:INFO:Importing libraries
2022-11-18 01:32:35,711:INFO:Copying training dataset
2022-11-18 01:32:35,715:INFO:Defining folds
2022-11-18 01:32:35,715:INFO:Declaring metric variables
2022-11-18 01:32:35,720:INFO:Importing untrained model
2022-11-18 01:32:35,723:INFO:Decision Tree Regressor Imported successfully
2022-11-18 01:32:35,729:INFO:Starting cross validation
2022-11-18 01:32:35,731:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:32:36,117:INFO:Calculating mean and std
2022-11-18 01:32:36,118:INFO:Creating metrics dataframe
2022-11-18 01:32:36,125:INFO:Finalizing model
2022-11-18 01:32:36,215:INFO:Uploading results into container
2022-11-18 01:32:36,217:INFO:Uploading model into container now
2022-11-18 01:32:36,226:INFO:master_model_container: 51
2022-11-18 01:32:36,226:INFO:display_container: 5
2022-11-18 01:32:36,226:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 01:32:36,226:INFO:create_model() successfully completed......................................
2022-11-18 01:33:15,263:INFO:Initializing create_model()
2022-11-18 01:33:15,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:33:15,264:INFO:Checking exceptions
2022-11-18 01:33:15,290:INFO:Importing libraries
2022-11-18 01:33:15,290:INFO:Copying training dataset
2022-11-18 01:33:15,294:INFO:Defining folds
2022-11-18 01:33:15,294:INFO:Declaring metric variables
2022-11-18 01:33:15,297:INFO:Importing untrained model
2022-11-18 01:33:15,301:INFO:Linear Regression Imported successfully
2022-11-18 01:33:15,310:INFO:Starting cross validation
2022-11-18 01:33:15,312:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:33:16,269:INFO:Calculating mean and std
2022-11-18 01:33:16,269:INFO:Creating metrics dataframe
2022-11-18 01:33:16,273:INFO:Finalizing model
2022-11-18 01:33:16,333:INFO:Uploading results into container
2022-11-18 01:33:16,334:INFO:Uploading model into container now
2022-11-18 01:33:16,343:INFO:master_model_container: 52
2022-11-18 01:33:16,343:INFO:display_container: 6
2022-11-18 01:33:16,343:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:33:16,343:INFO:create_model() successfully completed......................................
2022-11-18 01:34:33,038:INFO:Initializing create_model()
2022-11-18 01:34:33,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=None, round=2, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:34:33,039:INFO:Checking exceptions
2022-11-18 01:34:33,062:INFO:Importing libraries
2022-11-18 01:34:33,063:INFO:Copying training dataset
2022-11-18 01:34:33,067:INFO:Defining folds
2022-11-18 01:34:33,067:INFO:Declaring metric variables
2022-11-18 01:34:33,070:INFO:Importing untrained model
2022-11-18 01:34:33,074:INFO:Linear Regression Imported successfully
2022-11-18 01:34:33,080:INFO:Starting cross validation
2022-11-18 01:34:33,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:34:33,367:INFO:Calculating mean and std
2022-11-18 01:34:33,367:INFO:Creating metrics dataframe
2022-11-18 01:34:33,372:INFO:Finalizing model
2022-11-18 01:34:33,431:INFO:Uploading results into container
2022-11-18 01:34:33,432:INFO:Uploading model into container now
2022-11-18 01:34:33,447:INFO:master_model_container: 53
2022-11-18 01:34:33,447:INFO:display_container: 7
2022-11-18 01:34:33,447:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:34:33,447:INFO:create_model() successfully completed......................................
2022-11-18 01:34:46,766:INFO:Initializing create_model()
2022-11-18 01:34:46,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=None, round=3, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:34:46,766:INFO:Checking exceptions
2022-11-18 01:34:46,791:INFO:Importing libraries
2022-11-18 01:34:46,791:INFO:Copying training dataset
2022-11-18 01:34:46,795:INFO:Defining folds
2022-11-18 01:34:46,795:INFO:Declaring metric variables
2022-11-18 01:34:46,798:INFO:Importing untrained model
2022-11-18 01:34:46,803:INFO:Linear Regression Imported successfully
2022-11-18 01:34:46,809:INFO:Starting cross validation
2022-11-18 01:34:46,811:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:34:47,103:INFO:Calculating mean and std
2022-11-18 01:34:47,103:INFO:Creating metrics dataframe
2022-11-18 01:34:47,107:INFO:Finalizing model
2022-11-18 01:34:47,162:INFO:Uploading results into container
2022-11-18 01:34:47,163:INFO:Uploading model into container now
2022-11-18 01:34:47,173:INFO:master_model_container: 54
2022-11-18 01:34:47,175:INFO:display_container: 8
2022-11-18 01:34:47,175:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:34:47,175:INFO:create_model() successfully completed......................................
2022-11-18 01:36:13,503:INFO:Initializing create_model()
2022-11-18 01:36:13,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:36:13,504:INFO:Checking exceptions
2022-11-18 01:36:13,527:INFO:Importing libraries
2022-11-18 01:36:13,527:INFO:Copying training dataset
2022-11-18 01:36:13,531:INFO:Defining folds
2022-11-18 01:36:13,531:INFO:Declaring metric variables
2022-11-18 01:36:13,534:INFO:Importing untrained model
2022-11-18 01:36:13,538:INFO:Linear Regression Imported successfully
2022-11-18 01:36:13,543:INFO:Starting cross validation
2022-11-18 01:36:13,545:INFO:Cross validating with KFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:36:13,702:INFO:Calculating mean and std
2022-11-18 01:36:13,702:INFO:Creating metrics dataframe
2022-11-18 01:36:13,707:INFO:Finalizing model
2022-11-18 01:36:13,770:INFO:Uploading results into container
2022-11-18 01:36:13,770:INFO:Uploading model into container now
2022-11-18 01:36:13,779:INFO:master_model_container: 55
2022-11-18 01:36:13,779:INFO:display_container: 9
2022-11-18 01:36:13,779:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:36:13,779:INFO:create_model() successfully completed......................................
2022-11-18 01:36:16,605:INFO:Initializing create_model()
2022-11-18 01:36:16,605:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, estimator=lr, fold=None, round=3, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 01:36:16,605:INFO:Checking exceptions
2022-11-18 01:36:16,661:INFO:Importing libraries
2022-11-18 01:36:16,662:INFO:Copying training dataset
2022-11-18 01:36:16,666:INFO:Defining folds
2022-11-18 01:36:16,666:INFO:Declaring metric variables
2022-11-18 01:36:16,669:INFO:Importing untrained model
2022-11-18 01:36:16,672:INFO:Linear Regression Imported successfully
2022-11-18 01:36:16,681:INFO:Starting cross validation
2022-11-18 01:36:16,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 01:36:16,999:INFO:Calculating mean and std
2022-11-18 01:36:17,000:INFO:Creating metrics dataframe
2022-11-18 01:36:17,006:INFO:Finalizing model
2022-11-18 01:36:17,069:INFO:Uploading results into container
2022-11-18 01:36:17,071:INFO:Uploading model into container now
2022-11-18 01:36:17,080:INFO:master_model_container: 56
2022-11-18 01:36:17,080:INFO:display_container: 10
2022-11-18 01:36:17,081:INFO:LinearRegression(n_jobs=-1)
2022-11-18 01:36:17,081:INFO:create_model() successfully completed......................................
2022-11-18 01:36:49,533:INFO:Initializing plot_model()
2022-11-18 01:36:49,534:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LinearRegression(n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d449d5100>, system=True)
2022-11-18 01:36:49,534:INFO:Checking exceptions
2022-11-18 01:36:49,538:INFO:Preloading libraries
2022-11-18 01:36:49,538:INFO:Copying training dataset
2022-11-18 01:36:49,538:INFO:Plot type: parameter
2022-11-18 01:36:49,542:INFO:Visual Rendered Successfully
2022-11-18 01:36:49,648:INFO:plot_model() successfully completed......................................
